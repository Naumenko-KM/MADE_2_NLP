{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lab assignment 02"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Neural Machine Translation in the wild\n","In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n","\n","Basic approach using RNNs as encoder and decoder is implemented for you. \n","\n","Your ultimate task is to use the techniques we've covered, e.g.\n","\n","* Optimization enhancements (e.g. learning rate decay)\n","\n","* Transformer/CNN/<whatever you select> encoder (with or without positional encoding)\n","\n","* attention/self-attention mechanism\n","\n","* pretraining the language models (for decoder and encoder)\n","\n","* or just fine-tunning BART/ELECTRA/... ;)\n","\n","to improve the translation quality. \n","\n","__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n","\n","Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:05.686629Z","iopub.status.busy":"2023-05-22T08:21:05.685932Z","iopub.status.idle":"2023-05-22T08:21:05.699981Z","shell.execute_reply":"2023-05-22T08:21:05.698296Z","shell.execute_reply.started":"2023-05-22T08:21:05.686586Z"},"trusted":true},"outputs":[],"source":["# Thanks to YSDA NLP course team for the data\n","# (who thanks tilda and deephack teams for the data in their turn)\n","\n","import os\n","path_do_data = 'data.txt'\n","if not os.path.exists(path_do_data):\n","    print(\"Dataset not found locally. Downloading from github.\")\n","    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T12:02:30.223431Z","iopub.status.busy":"2023-05-20T12:02:30.223038Z","iopub.status.idle":"2023-05-20T12:02:30.228043Z","shell.execute_reply":"2023-05-20T12:02:30.227012Z","shell.execute_reply.started":"2023-05-20T12:02:30.223395Z"},"trusted":true},"outputs":[],"source":["# Baseline solution BLEU score is quite low. Try to achieve at least __21__ BLEU on the test set. \n","# The checkpoints are:\n","\n","# * __21__ - minimal score to submit the homework, 30% of points\n","\n","# * __25__ - good score, 70% of points\n","\n","# * __27__ - excellent score, 100% of points"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:08.838671Z","iopub.status.busy":"2023-05-22T08:21:08.835504Z","iopub.status.idle":"2023-05-22T08:21:20.410245Z","shell.execute_reply":"2023-05-22T08:21:20.409262Z","shell.execute_reply.started":"2023-05-22T08:21:08.838624Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import random\n","import matplotlib.pyplot as plt\n","import time\n","\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel\n","from transformers.modeling_outputs import BaseModelOutput\n","from transformers import T5Model, T5Tokenizer, T5Config, T5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from nltk.translate.bleu_score import corpus_bleu\n","from IPython.display import clear_output\n","\n","import wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:20.412551Z","iopub.status.busy":"2023-05-22T08:21:20.412181Z","iopub.status.idle":"2023-05-22T08:21:30.512988Z","shell.execute_reply":"2023-05-22T08:21:30.512083Z","shell.execute_reply.started":"2023-05-22T08:21:20.412508Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:34.056847Z","iopub.status.busy":"2023-05-22T08:21:34.056425Z","iopub.status.idle":"2023-05-22T08:21:34.293669Z","shell.execute_reply":"2023-05-22T08:21:34.292354Z","shell.execute_reply.started":"2023-05-22T08:21:34.056811Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num texts: 50000 50000\n","En max len: 518\n","Ru max len: 431\n"]}],"source":["with open('data.txt', 'r') as f:\n","    texts = f.read()\n","\n","texts = texts.split(sep='\\n')\n","texts = [row.split('\\t') for row in texts]\n","texts_en = [row[0] for row in texts if len(row) == 2]\n","texts_ru = [row[1] for row in texts if len(row) == 2]\n","\n","print('Num texts:', len(texts_en), len(texts_ru))\n","print('En max len:', max([len(row) for row in texts_en]))\n","print('Ru max len:', max([len(row) for row in texts_ru]))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:39.871990Z","iopub.status.busy":"2023-05-22T08:21:39.871632Z","iopub.status.idle":"2023-05-22T08:21:39.904807Z","shell.execute_reply":"2023-05-22T08:21:39.903267Z","shell.execute_reply.started":"2023-05-22T08:21:39.871958Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","MAX_LEN = 518\n","DEVICE"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:41.826085Z","iopub.status.busy":"2023-05-22T08:21:41.825115Z","iopub.status.idle":"2023-05-22T08:21:41.832698Z","shell.execute_reply":"2023-05-22T08:21:41.831557Z","shell.execute_reply.started":"2023-05-22T08:21:41.826032Z"},"trusted":true},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, texts_en, texts_ru):\n","        self.texts_en = texts_en\n","        self.texts_ru = texts_ru\n","        \n","    def __len__(self):\n","        return len(self.texts_en)\n","    \n","    def __getitem__(self, idx):\n","        return self.texts_en[idx], self.texts_ru[idx]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:42.786346Z","iopub.status.busy":"2023-05-22T08:21:42.785019Z","iopub.status.idle":"2023-05-22T08:21:42.850737Z","shell.execute_reply":"2023-05-22T08:21:42.849843Z","shell.execute_reply.started":"2023-05-22T08:21:42.786304Z"},"trusted":true},"outputs":[],"source":["train_texts_en, val_texts_en, train_texts_ru, val_texts_ru = train_test_split(texts_en, texts_ru, test_size=0.05, random_state=42)\n","train_texts_en, test_texts_en, train_texts_ru, test_texts_ru = train_test_split(train_texts_en, train_texts_ru, test_size=0.05, random_state=42)\n","\n","train_dataset = TextDataset(train_texts_en, train_texts_ru)\n","val_dataset = TextDataset(val_texts_en, val_texts_ru)\n","test_dataset = TextDataset(test_texts_en, test_texts_ru)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:54.945778Z","iopub.status.busy":"2023-05-22T08:21:54.945407Z","iopub.status.idle":"2023-05-22T08:21:54.950465Z","shell.execute_reply":"2023-05-22T08:21:54.949314Z","shell.execute_reply.started":"2023-05-22T08:21:54.945749Z"},"trusted":true},"outputs":[],"source":["n_epochs = 10\n","batch_size = 16\n","log_each_n_iterations = 200\n","generate_n = 1"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:22:24.346643Z","iopub.status.busy":"2023-05-22T08:22:24.345900Z","iopub.status.idle":"2023-05-22T08:22:41.260831Z","shell.execute_reply":"2023-05-22T08:22:41.259861Z","shell.execute_reply.started":"2023-05-22T08:22:24.346603Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"275bcba3a1e1427a9e19cfbb4da1389d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b9c1baa9ba546909e091b2ed414fbcf","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fd4c0bd8bdf4895999b17a22f1d3e03","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a78b825b4e4448308205773d6b9184ce","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1daae16b1f304a728f1eefcdf3bb6ccc","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/542M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34b3ab423cc14c0980f94cb1d8e16f3b","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68a739f609fc4b8ab59556b512891b1d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8c7465fab5d47718586f3d1f7dfb946","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"356edfba26f54391b9bce7415913aea6","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49514560097a4866867284a10b3f925d","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1856db51182b4a80b4259a2f6e8f4c6a","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size)\n","test_loader = DataLoader(test_dataset, batch_size)\n","generate_loader = DataLoader(val_dataset, generate_n, shuffle=True)\n","\n","\n","enc_name = 'distilbert-base-multilingual-cased'\n","dec_name = 't5-small'\n","\n","enc_tokenizer = AutoTokenizer.from_pretrained(enc_name)\n","encoder = AutoModel.from_pretrained(enc_name).to(DEVICE)\n","\n","dec_tokenizer = AutoTokenizer.from_pretrained(dec_name)\n","config = T5Config(vocab_size=dec_tokenizer.vocab_size, d_model=encoder.config.dim, decoder_start_token_id=0)\n","decoder = T5ForConditionalGeneration(config).to(DEVICE)\n","\n","for p in decoder.encoder.parameters():\n","    p.requires_grad = False\n","for p in decoder.decoder.parameters():\n","    p.requires_grad = True\n","\n","\n","LR = 1e-5\n","optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T11:39:10.142355Z","iopub.status.busy":"2023-05-22T11:39:10.141586Z","iopub.status.idle":"2023-05-22T11:39:10.151932Z","shell.execute_reply":"2023-05-22T11:39:10.150902Z","shell.execute_reply.started":"2023-05-22T11:39:10.142317Z"},"trusted":true},"outputs":[],"source":["def encode(texts):\n","    encoded_input = enc_tokenizer(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n","    with torch.no_grad():\n","        model_output = encoder(**encoded_input.to(encoder.device))\n","        embeddings = model_output.last_hidden_state\n","    return embeddings\n","\n","\n","def decode(embeddings, max_length=MAX_LEN, repetition_penalty=None, **kwargs):\n","    with torch.no_grad():\n","        out = decoder.generate(\n","            encoder_outputs=BaseModelOutput(last_hidden_state=embeddings), \n","            max_length=max_length, \n","            repetition_penalty=repetition_penalty,\n","            **kwargs\n","        )\n","        return [dec_tokenizer.decode(tokens, skip_special_tokens=True) for tokens in out]\n","    \n","\n","def calc_bleu(loader):\n","    original_text = []\n","    generated_text = []\n","    encoder.eval()\n","    decoder.eval()\n","\n","    for en, ru in tqdm(loader):\n","        embeds = encode(en)\n","        generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=None)\n","        \n","        original_text.extend(ru)\n","        generated_text.extend(generated)\n","\n","    return corpus_bleu([[text] for text in original_text], generated_text) * 100"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:36:07.921017Z","iopub.status.busy":"2023-05-22T08:36:07.920633Z","iopub.status.idle":"2023-05-22T11:23:49.040293Z","shell.execute_reply":"2023-05-22T11:23:49.039393Z","shell.execute_reply.started":"2023-05-22T08:36:07.920986Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaumenko-km\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.15.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20230522_083607-x71czkej</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/x71czkej' target=\"_blank\">experiment_5</a></strong> to <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/x71czkej' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/x71czkej</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[EPOCH 1]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:20<00:00,  4.14it/s] \n","100%|██████████| 149/149 [00:10<00:00, 14.56it/s]\n","100%|██████████| 157/157 [11:27<00:00,  4.38s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.5041274640384135 val bleu: 8.64111539902685\n","[EPOCH 2]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:03<00:00,  4.25it/s] \n","100%|██████████| 149/149 [00:10<00:00, 14.53it/s]\n","100%|██████████| 157/157 [09:31<00:00,  3.64s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.8748229190007153 val bleu: 17.644657721827222\n","[EPOCH 3]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:45<00:00,  4.37it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.70it/s]\n","100%|██████████| 157/157 [05:49<00:00,  2.22s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.6649316085264987 val bleu: 22.418755474772563\n","[EPOCH 4]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:41<00:00,  4.39it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.68it/s]\n","100%|██████████| 157/157 [04:37<00:00,  1.77s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.523114192005772 val bleu: 24.061367484599618\n","[EPOCH 5]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:45<00:00,  4.37it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.67it/s]\n","100%|██████████| 157/157 [05:46<00:00,  2.21s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.4490727786249762 val bleu: 24.897261313850684\n","[EPOCH 6]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:41<00:00,  4.40it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.62it/s]\n","100%|██████████| 157/157 [03:41<00:00,  1.41s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.3995933172686787 val bleu: 24.86191818786206\n","[EPOCH 7]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:41<00:00,  4.39it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.51it/s]\n","100%|██████████| 157/157 [04:03<00:00,  1.55s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.3704080693673768 val bleu: 25.050826147067745\n","[EPOCH 8]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:43<00:00,  4.38it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.49it/s]\n","100%|██████████| 157/157 [04:07<00:00,  1.58s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.34472791980577 val bleu: 25.7795889018896\n","[EPOCH 9]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:44<00:00,  4.37it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.52it/s]\n","100%|██████████| 157/157 [03:51<00:00,  1.48s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.334025996643425 val bleu: 25.659212332389142\n","[EPOCH 10]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:44<00:00,  4.38it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.51it/s]\n","100%|██████████| 157/157 [03:57<00:00,  1.51s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.3221652283764525 val bleu: 25.64166888834994\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▆▄▄▄▄▃▃▃▃▃▂▂▂▁▂▃▁▁▂▁▂▁▂▂▂▁▂▁▂▂▂▂▂▂▁▂▂▂▂</td></tr><tr><td>val bleu</td><td>▁▁▁▁▃▃▃▃▆▆▆▆▇▇▇▇████████████████████████</td></tr><tr><td>val loss</td><td>████▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.90227</td></tr><tr><td>val bleu</td><td>25.65921</td></tr><tr><td>val loss</td><td>1.33403</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_5</strong> at: <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/x71czkej' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/x71czkej</a><br/>Synced 6 W&B file(s), 141 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230522_083607-x71czkej/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"nlp-lab2\",\n","    notes=\"baseline\",\n","    name='experiment_5',\n","    entity='naumenko-km',\n","    \n","    # track hyperparameters and run metadata\n","    config={\n","    \"learning_rate\": LR,\n","    \"encoder\": enc_name,\n","    \"decoder\": dec_name,\n","    \"epochs\": n_epochs,\n","    }\n",")\n","best_bleu = 0\n","val_bleu = 0\n","mean_val_loss = 6\n","iters = 1\n","\n","for i in range(1, n_epochs + 1):\n","    print(f'[EPOCH {i}]')\n","    tqdm_iterator = tqdm(train_loader)\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        encoder.train()\n","        decoder.train()\n","        x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","        y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","        y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","        embeds = encoder(**x.to(encoder.device))\n","        embeds = embeds.last_hidden_state.to(DEVICE)\n","\n","        loss = decoder(\n","            encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n","            labels=y.input_ids,\n","            decoder_attention_mask=y.attention_mask,\n","            return_dict=True\n","        ).loss\n","                \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        wandb.log({\"batch loss\": loss.item(), \"val loss\": mean_val_loss, 'val bleu': val_bleu}, step=iters)\n","\n","        if iters % log_each_n_iterations == 0:\n","            encoder.eval()\n","            decoder.eval()    \n","            en, ru = next(iter(generate_loader))\n","            embeds = encode(en)\n","            generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=3.0)\n","            example = wandb.Html(data=f'batches: {iters} <br> True: {ru[0]} <br> Generated: {generated[0]}')\n","            wandb.log({\"texts\": example}, step=iters)\n","        iters += 1\n","\n","    tqdm_iterator = tqdm(test_loader)\n","    val_loss = []\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        encoder.eval()\n","        decoder.eval()\n","        with torch.no_grad():\n","            x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","            y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","            y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","            embeds = encoder(**x.to(encoder.device))\n","            embeds = embeds.last_hidden_state.to(DEVICE)\n","\n","            loss = decoder(\n","                encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n","                labels=y.input_ids,\n","                decoder_attention_mask=y.attention_mask,\n","                return_dict=True\n","            ).loss\n","            val_loss.append(loss.item())\n","    \n","    mean_val_loss = np.mean(val_loss)\n","    val_bleu = calc_bleu(val_loader)\n","    print(\"val loss:\", mean_val_loss, 'val bleu:', val_bleu)\n","    scheduler.step()\n","    \n","    if val_bleu > best_bleu:\n","        best_bleu = val_bleu\n","        # torch.save(encoder.state_dict(), 'encoder.pt')\n","        # torch.save(decoder.state_dict(), 'decoder.pt')\n","        # print(f'best loss improved!')\n","\n","wandb.finish()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T12:00:50.771514Z","iopub.status.busy":"2023-05-22T12:00:50.771023Z","iopub.status.idle":"2023-05-22T12:16:11.636908Z","shell.execute_reply":"2023-05-22T12:16:11.636037Z","shell.execute_reply.started":"2023-05-22T12:00:50.771483Z"},"trusted":true},"outputs":[{"data":{"text/html":["wandb version 0.15.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20230522_120050-ez9vaqcq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/ez9vaqcq' target=\"_blank\">experiment_5-2</a></strong> to <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/ez9vaqcq' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/ez9vaqcq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[EPOCH 1]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [10:40<00:00,  4.40it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.44it/s]\n","100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.2625626773642213 val bleu: 27.054727544870538\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80db3538c6a74d88bff2d3a8739df43e","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.007 MB of 0.055 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.124515…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▄▆▃▂▃▄▄▃▂▂▄▅▁▂▃▁▄▅▅▄▆▄▆▆▅▃▅▄▅▄▁█▅▅▂▅▂▃▆▅</td></tr><tr><td>val bleu</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.35028</td></tr><tr><td>val bleu</td><td>0</td></tr><tr><td>val loss</td><td>6</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_5-2</strong> at: <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/ez9vaqcq' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/ez9vaqcq</a><br/>Synced 6 W&B file(s), 14 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230522_120050-ez9vaqcq/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Дообучим еще 1 эпоху\n","LR = 5e-6\n","n_epochs = 1\n","optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=LR)\n","\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"nlp-lab2\",\n","    notes=\"baseline\",\n","    name='experiment_5-2',\n","    entity='naumenko-km',\n","    \n","    # track hyperparameters and run metadata\n","    config={\n","    \"learning_rate\": LR,\n","    \"encoder\": enc_name,\n","    \"decoder\": dec_name,\n","    \"epochs\": n_epochs,\n","    }\n",")\n","best_bleu = 0\n","val_bleu = 0\n","mean_val_loss = 6\n","iters = 1\n","\n","for i in range(1, n_epochs + 1):\n","    print(f'[EPOCH {i}]')\n","    tqdm_iterator = tqdm(train_loader)\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        encoder.train()\n","        decoder.train()\n","        x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","        y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","        y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","        embeds = encoder(**x.to(encoder.device))\n","        embeds = embeds.last_hidden_state.to(DEVICE)\n","\n","        loss = decoder(\n","            encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n","            labels=y.input_ids,\n","            decoder_attention_mask=y.attention_mask,\n","            return_dict=True\n","        ).loss\n","                \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        wandb.log({\"batch loss\": loss.item(), \"val loss\": mean_val_loss, 'val bleu': val_bleu}, step=iters)\n","\n","        if iters % log_each_n_iterations == 0:\n","            encoder.eval()\n","            decoder.eval()    \n","            en, ru = next(iter(generate_loader))\n","            embeds = encode(en)\n","            generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=3.0)\n","            example = wandb.Html(data=f'batches: {iters} <br> True: {ru[0]} <br> Generated: {generated[0]}')\n","            wandb.log({\"texts\": example}, step=iters)\n","        iters += 1\n","\n","    tqdm_iterator = tqdm(test_loader)\n","    val_loss = []\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        encoder.eval()\n","        decoder.eval()\n","        with torch.no_grad():\n","            x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","            y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","            y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","            embeds = encoder(**x.to(encoder.device))\n","            embeds = embeds.last_hidden_state.to(DEVICE)\n","\n","            loss = decoder(\n","                encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n","                labels=y.input_ids,\n","                decoder_attention_mask=y.attention_mask,\n","                return_dict=True\n","            ).loss\n","            val_loss.append(loss.item())\n","    \n","    mean_val_loss = np.mean(val_loss)\n","    val_bleu = calc_bleu(val_loader)\n","    print(\"val loss:\", mean_val_loss, 'val bleu:', val_bleu)\n","    scheduler.step()\n","    \n","    if val_bleu > best_bleu:\n","        best_bleu = val_bleu\n","        # torch.save(encoder.state_dict(), 'encoder.pt')\n","        # torch.save(decoder.state_dict(), 'decoder.pt')\n","        # print(f'best loss improved!')\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T12:18:15.915965Z","iopub.status.busy":"2023-05-22T12:18:15.915157Z","iopub.status.idle":"2023-05-22T12:22:04.172075Z","shell.execute_reply":"2023-05-22T12:22:04.171074Z","shell.execute_reply.started":"2023-05-22T12:18:15.915928Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 149/149 [03:47<00:00,  1.52s/it]\n"]},{"data":{"text/plain":["27.408179247778424"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["calc_bleu(test_loader)"]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"homework.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
