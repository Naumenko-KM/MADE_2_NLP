{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab assignment 02"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* Transformer/CNN/<whatever you select> encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language models (for decoder and encoder)\n",
    "\n",
    "* or just fine-tunning BART/ELECTRA/... ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting subword-nmt\n",
      "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: mock in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from subword-nmt) (4.0.3)\n",
      "Requirement already satisfied: tqdm in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from subword-nmt) (4.64.1)\n",
      "Installing collected packages: subword-nmt\n",
      "Successfully installed subword-nmt-0.3.8\n",
      "Requirement already satisfied: nltk in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from nltk) (2021.8.3)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.15.2-cp39-cp39-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchdata==0.6.1\n",
      "  Downloading torchdata-0.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 6.7 MB/s eta 0:00:01     |██████                          | 870 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torchtext) (2.26.0)\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 619.9 MB 47 kB/s  eta 0:00:01    |▌                               | 10.7 MB 4.2 MB/s eta 0:02:25     |▋                               | 11.5 MB 4.2 MB/s eta 0:02:25     |▉                               | 16.0 MB 3.7 MB/s eta 0:02:43     |█                               | 19.6 MB 2.6 MB/s eta 0:03:47     |█▊                              | 33.9 MB 2.8 MB/s eta 0:03:31     |██▋                             | 51.0 MB 2.2 MB/s eta 0:04:14     |████▏                           | 80.0 MB 5.0 MB/s eta 0:01:48     |████████▉                       | 170.8 MB 8.3 MB/s eta 0:00:54     |█████████                       | 172.8 MB 8.3 MB/s eta 0:00:54     |██████████                      | 192.1 MB 3.8 MB/s eta 0:01:52     |██████████                      | 195.5 MB 581 kB/s eta 0:12:11     |██████████▎                     | 198.4 MB 1.8 MB/s eta 0:03:59     |█████████████████               | 329.9 MB 4.0 MB/s eta 0:01:13     |█████████████████▌              | 340.0 MB 4.4 MB/s eta 0:01:04     |█████████████████▋              | 342.1 MB 4.4 MB/s eta 0:01:04     |█████████████████▊              | 342.8 MB 4.4 MB/s eta 0:01:03     |█████████████████▉              | 344.5 MB 4.4 MB/s eta 0:01:03     |██████████████████              | 349.6 MB 7.1 MB/s eta 0:00:39     |██████████████████▎             | 354.2 MB 3.7 MB/s eta 0:01:12     |██████████████████▍             | 355.2 MB 3.7 MB/s eta 0:01:12     |████████████████████            | 386.4 MB 3.7 MB/s eta 0:01:04     |████████████████████▏           | 391.5 MB 4.1 MB/s eta 0:00:56     |████████████████████▊           | 400.9 MB 4.9 MB/s eta 0:00:45     |█████████████████████           | 404.7 MB 3.4 MB/s eta 0:01:03     |█████████████████████           | 405.4 MB 3.4 MB/s eta 0:01:03     |█████████████████████           | 408.5 MB 5.0 MB/s eta 0:00:43     |█████████████████████▌          | 417.2 MB 2.9 MB/s eta 0:01:10     |█████████████████████▋          | 418.5 MB 2.0 MB/s eta 0:01:40     |█████████████████████▊          | 420.8 MB 2.7 MB/s eta 0:01:14     |██████████████████████▉         | 441.3 MB 2.9 MB/s eta 0:01:03     |█████████████████████████       | 485.7 MB 2.4 MB/s eta 0:00:56     |█████████████████████████▎      | 489.0 MB 3.4 MB/s eta 0:00:39     |█████████████████████████▉      | 500.4 MB 4.9 MB/s eta 0:00:25     |██████████████████████████      | 503.7 MB 4.9 MB/s eta 0:00:24     |██████████████████████████      | 505.8 MB 4.8 MB/s eta 0:00:24     |██████████████████████████▉     | 519.8 MB 3.1 MB/s eta 0:00:33     |███████████████████████████▋    | 535.6 MB 3.5 MB/s eta 0:00:25     |████████████████████████████▊   | 556.2 MB 4.9 MB/s eta 0:00:13     |████████████████████████████▉   | 558.8 MB 3.1 MB/s eta 0:00:20     |█████████████████████████████▊  | 576.5 MB 2.4 MB/s eta 0:00:18     |█████████████████████████████▉  | 578.2 MB 2.4 MB/s eta 0:00:18     |██████████████████████████████  | 583.2 MB 2.9 MB/s eta 0:00:13     |██████████████████████████████▎ | 586.6 MB 4.2 MB/s eta 0:00:08     |██████████████████████████████▌ | 589.9 MB 3.9 MB/s eta 0:00:08     |██████████████████████████████▌ | 590.4 MB 3.9 MB/s eta 0:00:08     |██████████████████████████████▌ | 590.8 MB 3.9 MB/s eta 0:00:08     |███████████████████████████████▉| 616.7 MB 2.8 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torchtext) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torchtext) (4.64.1)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 168.4 MB 272 kB/s eta 0:00:01   |                                | 368 kB 4.0 MB/s eta 0:00:43     |██                              | 10.2 MB 4.4 MB/s eta 0:00:36     |██▎                             | 12.1 MB 4.4 MB/s eta 0:00:36     |███                             | 15.7 MB 4.4 MB/s eta 0:00:35     |████████                        | 41.5 MB 3.2 MB/s eta 0:00:40     |█████████▌                      | 50.2 MB 4.6 MB/s eta 0:00:26     |██████████▍                     | 54.5 MB 4.6 MB/s eta 0:00:25     |██████████▍                     | 54.8 MB 4.6 MB/s eta 0:00:25     |███████████▌                    | 60.6 MB 3.4 MB/s eta 0:00:32     |████████████                    | 62.8 MB 3.4 MB/s eta 0:00:32     |█████████████▊                  | 72.2 MB 3.6 MB/s eta 0:00:27     |████████████████▉               | 88.3 MB 4.5 MB/s eta 0:00:18     |████████████████▉               | 88.6 MB 4.5 MB/s eta 0:00:18     |████████████████████            | 105.7 MB 4.1 MB/s eta 0:00:16     |█████████████████████           | 110.4 MB 5.5 MB/s eta 0:00:11     |█████████████████████▏          | 111.2 MB 5.5 MB/s eta 0:00:11     |██████████████████████▌         | 118.2 MB 2.9 MB/s eta 0:00:18     |███████████████████████▋        | 124.0 MB 2.9 MB/s eta 0:00:16     |████████████████████████████▊   | 150.9 MB 5.8 MB/s eta 0:00:04     |████████████████████████████▊   | 151.2 MB 5.8 MB/s eta 0:00:03     |█████████████████████████████   | 152.1 MB 5.8 MB/s eta 0:00:03     |█████████████████████████████   | 152.4 MB 5.8 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 63.3 MB 3.0 MB/s eta 0:00:012   |████▉                           | 9.6 MB 6.2 MB/s eta 0:00:09     |██████▎                         | 12.5 MB 5.5 MB/s eta 0:00:10     |███████                         | 13.9 MB 5.5 MB/s eta 0:00:10     |███████▋                        | 15.0 MB 5.5 MB/s eta 0:00:09     |████████                        | 15.7 MB 5.5 MB/s eta 0:00:09     |████████▏                       | 16.1 MB 5.5 MB/s eta 0:00:09     |███████████████████             | 37.7 MB 6.3 MB/s eta 0:00:05     |████████████████████████▊       | 48.9 MB 11.6 MB/s eta 0:00:02     |██████████████████████████████▏ | 59.8 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 54.6 MB 6.6 MB/s eta 0:00:01    |█████                           | 8.6 MB 7.2 MB/s eta 0:00:07     |████████▋                       | 14.7 MB 7.5 MB/s eta 0:00:06     |████████▉                       | 15.1 MB 7.5 MB/s eta 0:00:06     |████████████████▎               | 27.8 MB 4.5 MB/s eta 0:00:06     |████████████████▍               | 28.1 MB 5.1 MB/s eta 0:00:06     |████████████████▋               | 28.3 MB 5.1 MB/s eta 0:00:06     |████████████████████████▏       | 41.3 MB 5.6 MB/s eta 0:00:03     |█████████████████████████████▉  | 50.9 MB 5.7 MB/s eta 0:00:01     |██████████████████████████████▍ | 51.9 MB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torch==2.0.1->torchtext) (3.0.1)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 102.6 MB 6.4 MB/s eta 0:00:01   |                                | 327 kB 6.3 MB/s eta 0:00:17     |███████████▋                    | 37.3 MB 1.1 MB/s eta 0:00:57     |███████████████████▍            | 62.1 MB 4.1 MB/s eta 0:00:10     |█████████████████████████▏      | 80.6 MB 5.0 MB/s eta 0:00:05     |████████████████████████████████| 102.6 MB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8 MB 6.3 MB/s eta 0:00:01    |███████████████████████▏        | 8.6 MB 4.0 MB/s eta 0:00:01     |█████████████████████████████▎  | 10.9 MB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Requirement already satisfied: networkx in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torch==2.0.1->torchtext) (3.0)\n",
      "Requirement already satisfied: filelock in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torch==2.0.1->torchtext) (3.8.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 177.1 MB 258 kB/s eta 0:00:01   |▍                               | 2.4 MB 2.5 MB/s eta 0:01:11     |█▌                              | 8.1 MB 3.3 MB/s eta 0:00:52     |████▌                           | 24.9 MB 4.4 MB/s eta 0:00:35     |█████████▎                      | 51.4 MB 5.1 MB/s eta 0:00:25     |███████████▌                    | 63.7 MB 3.0 MB/s eta 0:00:39     |█████████████▊                  | 75.7 MB 5.5 MB/s eta 0:00:19     |█████████████▉                  | 76.7 MB 5.5 MB/s eta 0:00:19     |█████████████████               | 93.6 MB 4.6 MB/s eta 0:00:19     |███████████████████▍            | 107.2 MB 3.9 MB/s eta 0:00:18     |█████████████████████▏          | 117.3 MB 3.4 MB/s eta 0:00:18     |█████████████████████████       | 138.4 MB 1.0 MB/s eta 0:00:39     |████████████████████████████████| 176.9 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torch==2.0.1->torchtext) (4.3.0)\n",
      "Requirement already satisfied: sympy in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torch==2.0.1->torchtext) (1.11.1)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 173.2 MB 2.9 MB/s eta 0:00:01   |█▎                              | 6.9 MB 3.4 MB/s eta 0:00:49     |████████                        | 43.5 MB 2.6 MB/s eta 0:00:50     |█████████▏                      | 49.5 MB 3.0 MB/s eta 0:00:42     |██████████████                  | 75.2 MB 6.4 MB/s eta 0:00:16     |██████████████████▊             | 101.6 MB 4.1 MB/s eta 0:00:18     |███████████████████████████▍    | 148.5 MB 3.8 MB/s eta 0:00:07��███████████████████▋   | 154.5 MB 4.5 MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext) (59.8.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from torchdata==0.6.1->torchtext) (1.26.6)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.0 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-16.0.5.tar.gz (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from jinja2->torch==2.0.1->torchtext) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from requests->torchtext) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from requests->torchtext) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from requests->torchtext) (2.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mis-knaumenko/anaconda3/envs/ML/lib/python3.9/site-packages (from sympy->torch==2.0.1->torchtext) (1.2.1)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.5-py3-none-any.whl size=88192 sha256=003c5bff19936c931b0ae46be8887bff2ffc5da35c3427526b6b4301276dd5e5\n",
      "  Stored in directory: /home/mis-knaumenko/.cache/pip/wheels/d8/3a/a1/643264c1075b22759205027b760e0b1e85d975bfb333eef328\n",
      "Successfully built lit\n",
      "Installing collected packages: nvidia-cublas-cu11, lit, cmake, triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cusolver-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, torch, torchdata, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed cmake-3.26.3 lit-16.0.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "--2023-05-17 12:29:22--  https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12905334 (12M) [text/plain]\n",
      "Saving to: ‘data.txt’\n",
      "\n",
      "data.txt            100%[===================>]  12,31M  4,68MB/s    in 2,6s    \n",
      "\n",
      "2023-05-17 12:29:25 (4,68 MB/s) - ‘data.txt’ saved [12905334/12905334]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = 'data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline solution BLEU score is quite low. Try to achieve at least __21__ BLEU on the test set. \n",
    "# The checkpoints are:\n",
    "\n",
    "# * __21__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "# * __25__ - good score, 70% of points\n",
    "\n",
    "# * __27__ - excellent score, 100% of points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning! The code below is deeeeeeeply deprecated and is is provided only as simple guide.\n",
    "We suggest you to stick to most recent pipelines here, e.g. by Huggingface: \n",
    "* Example notebook: [link](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)\n",
    "* Converting your own dataset to specific format: [link](https://discuss.huggingface.co/t/correct-way-to-create-a-dataset-from-a-csv-file/15686/15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from transformers import T5Model, T5Tokenizer, T5Config, T5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num texts: 50000 50000\n",
      "En max len: 518\n",
      "Ru max len: 431\n"
     ]
    }
   ],
   "source": [
    "with open('data.txt', 'r') as f:\n",
    "    texts = f.read()\n",
    "\n",
    "texts = texts.split(sep='\\n')\n",
    "texts = [row.split('\\t') for row in texts]\n",
    "texts_en = [row[0] for row in texts if len(row) == 2]\n",
    "texts_ru = [row[1] for row in texts if len(row) == 2]\n",
    "\n",
    "print('Num texts:', len(texts_en), len(texts_ru))\n",
    "print('En max len:', max([len(row) for row in texts_en]))\n",
    "print('Ru max len:', max([len(row) for row in texts_ru]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MAX_LEN = 518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts_en, texts_ru):\n",
    "        self.texts_en = texts_en\n",
    "        self.texts_ru = texts_ru\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts_en)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts_en[idx], self.texts_ru[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_en, test_texts_en, train_texts_ru, test_texts_ru = train_test_split(texts_en, texts_ru, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TextDataset(train_texts_en, train_texts_ru)\n",
    "test_dataset = TextDataset(test_texts_en, test_texts_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 16\n",
    "log_each_n_iterations = 1000\n",
    "generate_n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, 16)\n",
    "generate_loader = DataLoader(test_dataset, generate_n, shuffle=True)\n",
    "\n",
    "\n",
    "enc_name = 'distilbert-base-multilingual-cased'\n",
    "dec_name = 't5-small'\n",
    "# dec_name = \"cointegrated/rut5-base-multitask\"\n",
    "\n",
    "enc_tokenizer = AutoTokenizer.from_pretrained(enc_name)\n",
    "encoder = AutoModel.from_pretrained(enc_name).to(DEVICE)\n",
    "\n",
    "dec_tokenizer = AutoTokenizer.from_pretrained(dec_name)\n",
    "decoder = AutoModelForSeq2SeqLM.from_pretrained(dec_name).to(DEVICE)\n",
    "# dec_tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-base-multitask\")\n",
    "config = T5Config(vocab_size=dec_tokenizer.vocab_size, d_model=encoder.config.dim, decoder_start_token_id=0)\n",
    "decoder = T5ForConditionalGeneration(config).to(DEVICE)\n",
    "\n",
    "for p in decoder.encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in decoder.decoder.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(texts):\n",
    "    encoded_input = enc_tokenizer(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = encoder(**encoded_input.to(encoder.device))\n",
    "        embeddings = model_output.last_hidden_state\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def decode(embeddings, max_length=MAX_LEN, repetition_penalty=3.0, **kwargs):\n",
    "    with torch.no_grad():\n",
    "        out = decoder.generate(\n",
    "            encoder_outputs=BaseModelOutput(last_hidden_state=embeddings), \n",
    "            max_length=max_length, \n",
    "            repetition_penalty=repetition_penalty,\n",
    "            **kwargs\n",
    "        )\n",
    "        return [dec_tokenizer.decode(tokens, skip_special_tokens=True) for tokens in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Located inside a condo 2,5 km from Pernambuco Beach, Guarujá House offers an outdoor pool and barbecue facilities.',)\n",
      "('Дом для отпуска Guarujá House находится в кономиниуме, в 2,5 км от пляжа Пернамбуку. К услугам гостей открытый бассейн и принадлежности для барбекю.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.92204:   0%|          | 1/40000 [00:02<21:12:05,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Featuring a balcony, all units have a seating and dining area.',)\n",
      "('Во всех апартаментах есть балкон, гостиный уголок и обеденная зона.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.58915:   0%|          | 2/40000 [00:03<15:42:13,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Only 500 metres from the UNESCO-protected centre of Trogir, it offers free parking and air-conditioned accommodation with free Wi-Fi.',)\n",
      "('К услугам гостей номера и апартаменты с кондиционером и бесплатным Wi-Fi, а также бесплатная парковка. Всего в 500 метрах находится центр Трогира, внесенный в список объектов Всемирного наследия ЮНЕСКО.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.32788:   0%|          | 3/40000 [00:04<14:28:57,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Free private parking is available on site.',)\n",
      "('На территории обустроена бесплатная частная парковка.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.10736:   0%|          | 4/40000 [00:05<13:24:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Guests can enjoy a meal at the on-site restaurant, which offers à la carte options. Room service is provided.',)\n",
      "('На территории комплекса открыт ресторан с обслуживанием по меню, а для дополнительного удобства гостей осуществляется доставка еды и напитков в номер.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9.95268:   0%|          | 5/40000 [00:06<13:37:34,  1.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('It is a 10-minute drive from Jiuzhou Port and a 30-minute drive from Hengqin Port or Chimelong Ocean International Tourist Resort.',)\n",
      "('Поездка до порта Цзючжоу займет 10 минут, а за 30 минут можно доехать до порта Хэнцзинь и международного туристического курорта Chimelong Ocean.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9.78891:   0%|          | 6/40000 [00:07<13:58:24,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The beach of Agia Triada is 1.2 km away from Venere Apartments.',)\n",
      "('Пляж Агиа Триада находится в 1,2 км от апартаментов Venere.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9.85064:   0%|          | 7/40000 [00:09<14:45:17,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('An array of activities can be enjoyed on site or in the surroundings, including snorkelling and canoeing.',)\n",
      "('На территории и в окрестностях популярны различные виды активного отдыха, в том числе сноркелинг и катание на каноэ.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9.85064:   0%|          | 7/40000 [00:09<15:48:23,  1.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_63900/462862777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history = []\n",
    "iters = 1\n",
    "\n",
    "for i in range(1, n_epochs + 1):\n",
    "    print(f'[EPOCH {i}]')\n",
    "    tqdm_iterator = tqdm(train_loader)\n",
    "\n",
    "    for text_en_batch, text_ru_batch in tqdm_iterator:\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n",
    "        y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n",
    "\n",
    "        y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг\n",
    "        embeds = encoder(**x.to(encoder.device))\n",
    "        embeds = embeds.last_hidden_state.to(DEVICE)\n",
    "\n",
    "        loss = decoder(\n",
    "            encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n",
    "            labels=y.input_ids,\n",
    "            decoder_attention_mask=y.attention_mask,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "        \n",
    "        tqdm_iterator.set_description(f'{round(loss.item(), 5)}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_history.append((iters, loss.item()))\n",
    "        \n",
    "        if iters % log_each_n_iterations == 0:\n",
    "            clear_output()\n",
    "            print(f'[EPOCH {i}]')\n",
    "            encoder.eval()\n",
    "            decoder.eval()\n",
    "            \n",
    "            train_it, train_loss = zip(*train_history)\n",
    "            \n",
    "            plt.plot(train_it, train_loss, color='blue', label='train loss')\n",
    "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "            plt.grid()\n",
    "            plt.title('loss')\n",
    "            plt.show()\n",
    "            \n",
    "            en, ru = next(iter(generate_loader))\n",
    "            embeds = encode(en)\n",
    "            generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=None)\n",
    "            print(ru)\n",
    "            print('\\n\\n'.join(generated))\n",
    "        \n",
    "        iters += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "for en, ru in tqdm(generate_loader):\n",
    "    embeds = encode(en)\n",
    "    generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=None)\n",
    "    \n",
    "    original_text.extend(ru)\n",
    "    generated_text.extend(generated)\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Апарт-отель Royal Bansko хорошо подходит для зимнего отдыха. К услугам гостей детская комната и пункт проката автомобилей.',\n",
       " \"Гостевой дом Jemal's находится в поселке Махинджаури, на берегу Черного моря, всего в 100 метрах от пляжа Махинджаури.\",\n",
       " 'На завтрак подают свежие фрукты, домашние пирожные, йогурт и хлопья.',\n",
       " 'Гостевой дом Orlinds Tunas находится в 5 минутах ходьбы от пещеры Срити и в 1 часе езды от улицы Малиоборо и международного аэропорта Ади Сучипто.',\n",
       " 'Во всех апартаментах имеется мини-кухня, отдельная гостиная зона и телевизор с плоским экраном с кабельными каналами. Из окон открывается вид на океан.',\n",
       " 'Современные апартаменты Belavista расположены в 600 метрах от набережной в городе Сплит. К услугам гостей бесплатный Wi-Fi, отдельный балкон и бесплатная частная парковка.',\n",
       " 'К услугам гостей телевизор, DVD-плеер, терраса и обеденный стол.',\n",
       " 'В распоряжении жильцов — гостиный уголок, телевизор с плоским экраном, гардеробная и ванная комната с душем и унитазом.',\n",
       " 'Мини-кухня с обеденной зоной оборудована холодильником.',\n",
       " 'Современные номера оснащены кондиционером, телевизором со спутниковыми каналами и мини-баром. Полы в них деревянные или выложены плиткой.']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.139920232081806"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
