{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lab assignment 02"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Neural Machine Translation in the wild\n","In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n","\n","Basic approach using RNNs as encoder and decoder is implemented for you. \n","\n","Your ultimate task is to use the techniques we've covered, e.g.\n","\n","* Optimization enhancements (e.g. learning rate decay)\n","\n","* Transformer/CNN/<whatever you select> encoder (with or without positional encoding)\n","\n","* attention/self-attention mechanism\n","\n","* pretraining the language models (for decoder and encoder)\n","\n","* or just fine-tunning BART/ELECTRA/... ;)\n","\n","to improve the translation quality. \n","\n","__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n","\n","Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:46:47.588005Z","iopub.status.busy":"2023-05-22T02:46:47.587276Z","iopub.status.idle":"2023-05-22T02:46:49.169115Z","shell.execute_reply":"2023-05-22T02:46:49.167785Z","shell.execute_reply.started":"2023-05-22T02:46:47.587958Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset not found locally. Downloading from github.\n","--2023-05-22 02:46:48--  https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12905334 (12M) [text/plain]\n","Saving to: ‘data.txt’\n","\n","data.txt            100%[===================>]  12.31M  --.-KB/s    in 0.1s    \n","\n","2023-05-22 02:46:49 (111 MB/s) - ‘data.txt’ saved [12905334/12905334]\n","\n"]}],"source":["# Thanks to YSDA NLP course team for the data\n","# (who thanks tilda and deephack teams for the data in their turn)\n","\n","import os\n","path_do_data = 'data.txt'\n","\n","if not os.path.exists(path_do_data):\n","    print(\"Dataset not found locally. Downloading from github.\")\n","    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:46:49.177535Z","iopub.status.busy":"2023-05-22T02:46:49.175088Z","iopub.status.idle":"2023-05-22T02:46:49.191909Z","shell.execute_reply":"2023-05-22T02:46:49.190860Z","shell.execute_reply.started":"2023-05-22T02:46:49.177494Z"},"trusted":true},"outputs":[],"source":["# Baseline solution BLEU score is quite low. Try to achieve at least __21__ BLEU on the test set. \n","# The checkpoints are:\n","\n","# * __21__ - minimal score to submit the homework, 30% of points\n","\n","# * __25__ - good score, 70% of points\n","\n","# * __27__ - excellent score, 100% of points"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Warning! The code below is deeeeeeeply deprecated and is is provided only as simple guide.\n","We suggest you to stick to most recent pipelines here, e.g. by Huggingface: \n","* Example notebook: [link](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)\n","* Converting your own dataset to specific format: [link](https://discuss.huggingface.co/t/correct-way-to-create-a-dataset-from-a-csv-file/15686/15)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:46:49.197788Z","iopub.status.busy":"2023-05-22T02:46:49.196990Z","iopub.status.idle":"2023-05-22T02:47:02.302337Z","shell.execute_reply":"2023-05-22T02:47:02.301430Z","shell.execute_reply.started":"2023-05-22T02:46:49.197749Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import random\n","import matplotlib.pyplot as plt\n","import time\n","\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel\n","from transformers.modeling_outputs import BaseModelOutput\n","from transformers import T5Model, T5Tokenizer, T5Config, T5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from nltk.translate.bleu_score import corpus_bleu\n","from IPython.display import clear_output\n","\n","import wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:47:02.304886Z","iopub.status.busy":"2023-05-22T02:47:02.304520Z","iopub.status.idle":"2023-05-22T02:47:14.276661Z","shell.execute_reply":"2023-05-22T02:47:14.275764Z","shell.execute_reply.started":"2023-05-22T02:47:02.304853Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:47:16.333939Z","iopub.status.busy":"2023-05-22T02:47:16.333563Z","iopub.status.idle":"2023-05-22T02:47:16.509658Z","shell.execute_reply":"2023-05-22T02:47:16.508710Z","shell.execute_reply.started":"2023-05-22T02:47:16.333908Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num texts: 50000 50000\n","En max len: 518\n","Ru max len: 431\n"]}],"source":["with open('data.txt', 'r') as f:\n","    texts = f.read()\n","\n","texts = texts.split(sep='\\n')\n","texts = [row.split('\\t') for row in texts]\n","texts_en = [row[0] for row in texts if len(row) == 2]\n","texts_ru = [row[1] for row in texts if len(row) == 2]\n","\n","print('Num texts:', len(texts_en), len(texts_ru))\n","print('En max len:', max([len(row) for row in texts_en]))\n","print('Ru max len:', max([len(row) for row in texts_ru]))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:47:19.732892Z","iopub.status.busy":"2023-05-22T02:47:19.730456Z","iopub.status.idle":"2023-05-22T02:47:19.761849Z","shell.execute_reply":"2023-05-22T02:47:19.760873Z","shell.execute_reply.started":"2023-05-22T02:47:19.732844Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","MAX_LEN = 518\n","DEVICE"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:47:21.311241Z","iopub.status.busy":"2023-05-22T02:47:21.310698Z","iopub.status.idle":"2023-05-22T02:47:21.316897Z","shell.execute_reply":"2023-05-22T02:47:21.315853Z","shell.execute_reply.started":"2023-05-22T02:47:21.311208Z"},"trusted":true},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, texts_en, texts_ru):\n","        self.texts_en = texts_en\n","        self.texts_ru = texts_ru\n","        \n","    def __len__(self):\n","        return len(self.texts_en)\n","    \n","    def __getitem__(self, idx):\n","        return self.texts_en[idx], self.texts_ru[idx]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:47:24.257376Z","iopub.status.busy":"2023-05-22T02:47:24.257012Z","iopub.status.idle":"2023-05-22T02:47:24.322359Z","shell.execute_reply":"2023-05-22T02:47:24.321462Z","shell.execute_reply.started":"2023-05-22T02:47:24.257348Z"},"trusted":true},"outputs":[],"source":["train_texts_en, val_texts_en, train_texts_ru, val_texts_ru = train_test_split(texts_en, texts_ru, test_size=0.05, random_state=42)\n","train_texts_en, test_texts_en, train_texts_ru, test_texts_ru = train_test_split(train_texts_en, train_texts_ru, test_size=0.05, random_state=42)\n","\n","train_dataset = TextDataset(train_texts_en, train_texts_ru)\n","val_dataset = TextDataset(val_texts_en, val_texts_ru)\n","test_dataset = TextDataset(test_texts_en, test_texts_ru)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:47:28.600394Z","iopub.status.busy":"2023-05-22T02:47:28.599798Z","iopub.status.idle":"2023-05-22T02:47:28.604428Z","shell.execute_reply":"2023-05-22T02:47:28.603517Z","shell.execute_reply.started":"2023-05-22T02:47:28.600362Z"},"trusted":true},"outputs":[],"source":["n_epochs = 4\n","batch_size = 4\n","log_each_n_iterations = 200\n","generate_n = 1"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:47:40.785514Z","iopub.status.busy":"2023-05-22T02:47:40.785161Z","iopub.status.idle":"2023-05-22T02:47:59.899588Z","shell.execute_reply":"2023-05-22T02:47:59.898613Z","shell.execute_reply.started":"2023-05-22T02:47:40.785487Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be734798f1df4a52a4ffcd4ac7382916","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52996994b38b4fa6b04e59b6d810f902","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c6f863d942f44efb46ddff4877a8677","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/source.spm:   0%|          | 0.00/803k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ddcbb27197994bb1a0b4b3e676c652de","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/target.spm:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6db913a838684e67982f92983995c92a","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/2.60M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c39dfa74d22a413f8a1879da6eda948f","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/307M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43c1216291ec4f79ad0bd67fd9f6d4ee","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size)\n","test_loader = DataLoader(test_dataset, batch_size)\n","generate_loader = DataLoader(val_dataset, generate_n, shuffle=True)\n","\n","\n","model_name = 'Helsinki-NLP/opus-mt-en-ru'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(DEVICE)\n","\n","LR = 1e-6\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:47:59.902101Z","iopub.status.busy":"2023-05-22T02:47:59.901701Z","iopub.status.idle":"2023-05-22T02:47:59.910550Z","shell.execute_reply":"2023-05-22T02:47:59.909562Z","shell.execute_reply.started":"2023-05-22T02:47:59.902069Z"},"trusted":true},"outputs":[],"source":["def decode(x, max_length=MAX_LEN, repetition_penalty=3.0, **kwargs):\n","    with torch.no_grad():\n","        out = model.generate(\n","            **x, \n","            max_length=max_length, \n","            repetition_penalty=repetition_penalty,\n","            **kwargs\n","        )\n","        return [tokenizer.decode(tokens, skip_special_tokens=True).replace('▁', ' ') for tokens in out]\n","    \n","    \n","\n","def calc_bleu(loader):\n","    original_text = []\n","    generated_text = []\n","    model.eval()\n","    for en, ru in tqdm(loader):\n","        x = tokenizer(en, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","        with torch.no_grad():\n","            out = model.generate(**x, repetition_penalty=3.0)\n","            generated = [tokenizer.decode(tokens, skip_special_tokens=True) for tokens in out]\n","            original_text.extend(ru)\n","            generated_text.extend(generated)\n","    return corpus_bleu([[text] for text in original_text], generated_text) * 100"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:48:01.913753Z","iopub.status.busy":"2023-05-22T02:48:01.912753Z","iopub.status.idle":"2023-05-22T02:52:00.191817Z","shell.execute_reply":"2023-05-22T02:52:00.190833Z","shell.execute_reply.started":"2023-05-22T02:48:01.913703Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/594 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","100%|██████████| 594/594 [03:56<00:00,  2.51it/s]\n"]},{"data":{"text/plain":["46.7290569363296"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["calc_bleu(test_loader)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T02:52:18.149847Z","iopub.status.busy":"2023-05-22T02:52:18.149449Z","iopub.status.idle":"2023-05-22T07:17:00.472282Z","shell.execute_reply":"2023-05-22T07:17:00.471220Z","shell.execute_reply.started":"2023-05-22T02:52:18.149796Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaumenko-km\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.15.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20230522_025218-uye1xycl</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/uye1xycl' target=\"_blank\">helsinki_09</a></strong> to <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/uye1xycl' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/uye1xycl</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[EPOCH 1]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 11281/11281 [14:46<00:00, 12.73it/s] \n","100%|██████████| 625/625 [00:14<00:00, 43.50it/s]\n","100%|██████████| 625/625 [43:03<00:00,  4.13s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 0.6486102778911591 val bleu: 42.02435744372206\n","best loss improved!\n","[EPOCH 2]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 11281/11281 [16:03<00:00, 11.71it/s] \n","100%|██████████| 625/625 [00:14<00:00, 42.01it/s]\n","100%|██████████| 625/625 [51:17<00:00,  4.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 0.545962978219986 val bleu: 27.679329695896886\n","[EPOCH 3]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 11281/11281 [16:50<00:00, 11.16it/s] \n","100%|██████████| 625/625 [00:14<00:00, 42.99it/s]\n","100%|██████████| 625/625 [51:52<00:00,  4.98s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 0.511704444694519 val bleu: 23.740646338113578\n","[EPOCH 4]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 11281/11281 [16:55<00:00, 11.11it/s] \n","100%|██████████| 625/625 [00:14<00:00, 42.40it/s]\n","100%|██████████| 625/625 [52:10<00:00,  5.01s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 0.49706644332408906 val bleu: 22.64839369753393\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"239dbc77e6a541dbb7cb9188e668a81b","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.134 MB of 0.134 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▇▅▆▅▄▃▃▂▃▃▃▃▃▂▂▃▃▂▃▂▃▂▃▃▃▁▄▂▃▁▃▁▂▂▂▂▁▃▃</td></tr><tr><td>val bleu</td><td>▁▁▁▁▁▁▁▁▁▁██████████▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>val loss</td><td>██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.28102</td></tr><tr><td>val bleu</td><td>23.74065</td></tr><tr><td>val loss</td><td>0.5117</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">helsinki_09</strong> at: <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/uye1xycl' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/uye1xycl</a><br/>Synced 6 W&B file(s), 225 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230522_025218-uye1xycl/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"nlp-lab2\",\n","    entity='naumenko-km',\n","    notes=\"helsinki\",\n","    name='helsinki_09',\n","    \n","    # track hyperparameters and run metadata\n","    config={\n","    \"learning_rate\": LR,\n","    \"encoder\": model_name,\n","    \"decoder\": model_name,\n","    \"epochs\": n_epochs,\n","    }\n",")\n","\n","best_bleu = 0\n","val_bleu = 0\n","mean_val_loss = 10\n","iters = 1\n","bad_texts = [\n","    'In the village of Ystalyfera, Ty-Ni Guest House lies just outside the Brecon Beacons National Park and overlooks the Darren Mountain. Around 30 minutes’ drive from Swansea and Mumbles, this guest house provides free parking and WiFi.',\n","    'A microwave and a small fridge are included in each room at the Sun Bridge Inn Pine Bluff. A cable TV is also provided.'\n","]\n","\n","for i in range(1, n_epochs + 1):\n","    print(f'[EPOCH {i}]')\n","    tqdm_iterator = tqdm(train_loader)\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        model.train()\n","        x = tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","        y = tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","        y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг\n","        loss = model(\n","            **x,\n","            labels=y.input_ids,\n","            decoder_attention_mask=y.attention_mask,\n","            return_dict=True\n","        ).loss\n","                \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        wandb.log({\"batch loss\": loss.item(), \"val loss\": mean_val_loss, 'val bleu': val_bleu}, step=iters)\n","\n","        if iters % log_each_n_iterations == 0:\n","            model.eval()\n","            en, ru = next(iter(generate_loader))    \n","            x = tokenizer(en, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","            out = model.generate(**x, repetition_penalty=3.0)\n","            generated = [tokenizer.decode(tokens, skip_special_tokens=True) for tokens in out]\n","            \n","            example = wandb.Html(data=f'batches: {iters} <br> True: {ru[0]} <br> Generated: {generated[0]}')\n","            wandb.log({\"texts\": example}, step=iters)\n","        iters += 1\n","\n","    tqdm_iterator = tqdm(val_loader)\n","    val_loss = []\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        model.eval()\n","        with torch.no_grad():\n","            x = tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","            y = tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","            y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг\n","            loss = model(\n","                **x,\n","                labels=y.input_ids,\n","                decoder_attention_mask=y.attention_mask,\n","                return_dict=True\n","            ).loss\n","            val_loss.append(loss.item())\n","    \n","    mean_val_loss = np.mean(val_loss)\n","    val_bleu = calc_bleu(val_loader)\n","    print(\"val loss:\", mean_val_loss, 'val bleu:', val_bleu)\n","    scheduler.step()\n","    \n","    if val_bleu > best_bleu:\n","        best_bleu = val_bleu\n","        # torch.save(model.state_dict(), 'model_train.pt')\n","        print(f'best loss improved!')\n","\n","wandb.finish()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T07:17:00.474231Z","iopub.status.busy":"2023-05-22T07:17:00.473873Z","iopub.status.idle":"2023-05-22T08:06:06.680085Z","shell.execute_reply":"2023-05-22T08:06:06.678867Z","shell.execute_reply.started":"2023-05-22T07:17:00.474194Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 594/594 [49:03<00:00,  4.96s/it]\n"]},{"data":{"text/plain":["23.259726473443617"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["calc_bleu(test_loader)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"homework.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
