{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lab assignment 02"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Neural Machine Translation in the wild\n","In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n","\n","Basic approach using RNNs as encoder and decoder is implemented for you. \n","\n","Your ultimate task is to use the techniques we've covered, e.g.\n","\n","* Optimization enhancements (e.g. learning rate decay)\n","\n","* Transformer/CNN/<whatever you select> encoder (with or without positional encoding)\n","\n","* attention/self-attention mechanism\n","\n","* pretraining the language models (for decoder and encoder)\n","\n","* or just fine-tunning BART/ELECTRA/... ;)\n","\n","to improve the translation quality. \n","\n","__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n","\n","Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:52:28.720602Z","iopub.status.busy":"2023-05-20T23:52:28.720183Z","iopub.status.idle":"2023-05-20T23:52:28.727856Z","shell.execute_reply":"2023-05-20T23:52:28.726942Z","shell.execute_reply.started":"2023-05-20T23:52:28.720567Z"},"trusted":true},"outputs":[],"source":["# Thanks to YSDA NLP course team for the data\n","# (who thanks tilda and deephack teams for the data in their turn)\n","\n","import os\n","path_do_data = 'data.txt'\n","if not os.path.exists(path_do_data):\n","    print(\"Dataset not found locally. Downloading from github.\")\n","    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T12:02:30.223431Z","iopub.status.busy":"2023-05-20T12:02:30.223038Z","iopub.status.idle":"2023-05-20T12:02:30.228043Z","shell.execute_reply":"2023-05-20T12:02:30.227012Z","shell.execute_reply.started":"2023-05-20T12:02:30.223395Z"},"trusted":true},"outputs":[],"source":["# Baseline solution BLEU score is quite low. Try to achieve at least __21__ BLEU on the test set. \n","# The checkpoints are:\n","\n","# * __21__ - minimal score to submit the homework, 30% of points\n","\n","# * __25__ - good score, 70% of points\n","\n","# * __27__ - excellent score, 100% of points"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:45:47.912855Z","iopub.status.busy":"2023-05-20T23:45:47.912254Z","iopub.status.idle":"2023-05-20T23:45:59.653953Z","shell.execute_reply":"2023-05-20T23:45:59.652982Z","shell.execute_reply.started":"2023-05-20T23:45:47.912796Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import random\n","import matplotlib.pyplot as plt\n","import time\n","\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel\n","from transformers.modeling_outputs import BaseModelOutput\n","from transformers import T5Model, T5Tokenizer, T5Config, T5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from nltk.translate.bleu_score import corpus_bleu\n","from IPython.display import clear_output\n","\n","import wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:45:59.656069Z","iopub.status.busy":"2023-05-20T23:45:59.655726Z","iopub.status.idle":"2023-05-20T23:46:12.792764Z","shell.execute_reply":"2023-05-20T23:46:12.791777Z","shell.execute_reply.started":"2023-05-20T23:45:59.656038Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaumenko-km\u001b[0m (\u001b[33mvector2text\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:46:29.817047Z","iopub.status.busy":"2023-05-20T23:46:29.816684Z","iopub.status.idle":"2023-05-20T23:46:29.998175Z","shell.execute_reply":"2023-05-20T23:46:29.997182Z","shell.execute_reply.started":"2023-05-20T23:46:29.817017Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num texts: 50000 50000\n","En max len: 518\n","Ru max len: 431\n"]}],"source":["with open('data.txt', 'r') as f:\n","    texts = f.read()\n","\n","texts = texts.split(sep='\\n')\n","texts = [row.split('\\t') for row in texts]\n","texts_en = [row[0] for row in texts if len(row) == 2]\n","texts_ru = [row[1] for row in texts if len(row) == 2]\n","\n","print('Num texts:', len(texts_en), len(texts_ru))\n","print('En max len:', max([len(row) for row in texts_en]))\n","print('Ru max len:', max([len(row) for row in texts_ru]))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:46:31.037161Z","iopub.status.busy":"2023-05-20T23:46:31.036806Z","iopub.status.idle":"2023-05-20T23:46:31.065715Z","shell.execute_reply":"2023-05-20T23:46:31.064578Z","shell.execute_reply.started":"2023-05-20T23:46:31.037131Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda', index=4)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["DEVICE = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n","MAX_LEN = 518\n","DEVICE"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:46:32.083809Z","iopub.status.busy":"2023-05-20T23:46:32.083434Z","iopub.status.idle":"2023-05-20T23:46:32.090381Z","shell.execute_reply":"2023-05-20T23:46:32.089111Z","shell.execute_reply.started":"2023-05-20T23:46:32.083777Z"},"trusted":true},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, texts_en, texts_ru):\n","        self.texts_en = texts_en\n","        self.texts_ru = texts_ru\n","        \n","    def __len__(self):\n","        return len(self.texts_en)\n","    \n","    def __getitem__(self, idx):\n","        return self.texts_en[idx], self.texts_ru[idx]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:52:55.570735Z","iopub.status.busy":"2023-05-20T23:52:55.570342Z","iopub.status.idle":"2023-05-20T23:52:55.638213Z","shell.execute_reply":"2023-05-20T23:52:55.637265Z","shell.execute_reply.started":"2023-05-20T23:52:55.570702Z"},"trusted":true},"outputs":[],"source":["train_texts_en, val_texts_en, train_texts_ru, val_texts_ru = train_test_split(texts_en, texts_ru, test_size=0.05, random_state=42)\n","train_texts_en, test_texts_en, train_texts_ru, test_texts_ru = train_test_split(train_texts_en, train_texts_ru, test_size=0.05, random_state=42)\n","\n","train_dataset = TextDataset(train_texts_en, train_texts_ru)\n","val_dataset = TextDataset(val_texts_en, val_texts_ru)\n","test_dataset = TextDataset(test_texts_en, test_texts_ru)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:53:02.921737Z","iopub.status.busy":"2023-05-20T23:53:02.921363Z","iopub.status.idle":"2023-05-20T23:53:02.926688Z","shell.execute_reply":"2023-05-20T23:53:02.925714Z","shell.execute_reply.started":"2023-05-20T23:53:02.921706Z"},"trusted":true},"outputs":[],"source":["n_epochs = 10\n","batch_size = 16\n","log_each_n_iterations = 200\n","generate_n = 1"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:53:05.483350Z","iopub.status.busy":"2023-05-20T23:53:05.482991Z","iopub.status.idle":"2023-05-20T23:53:23.951363Z","shell.execute_reply":"2023-05-20T23:53:23.950341Z","shell.execute_reply.started":"2023-05-20T23:53:05.483320Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size)\n","test_loader = DataLoader(test_dataset, batch_size)\n","generate_loader = DataLoader(val_dataset, generate_n, shuffle=True)\n","\n","\n","enc_name = 'distilbert-base-multilingual-cased'\n","dec_name = 't5-small'\n","# dec_name = \"cointegrated/rut5-base-multitask\"\n","\n","enc_tokenizer = AutoTokenizer.from_pretrained(enc_name)\n","encoder = AutoModel.from_pretrained(enc_name).to(DEVICE)\n","\n","dec_tokenizer = AutoTokenizer.from_pretrained(dec_name)\n","decoder = AutoModelForSeq2SeqLM.from_pretrained(dec_name).to(DEVICE)\n","# dec_tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-base-multitask\")\n","config = T5Config(vocab_size=dec_tokenizer.vocab_size, d_model=encoder.config.dim, decoder_start_token_id=0)\n","decoder = T5ForConditionalGeneration(config).to(DEVICE)\n","\n","for p in decoder.encoder.parameters():\n","    p.requires_grad = False\n","for p in decoder.decoder.parameters():\n","    p.requires_grad = True\n","\n","\n","LR = 1e-5\n","optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:53:23.953785Z","iopub.status.busy":"2023-05-20T23:53:23.953315Z","iopub.status.idle":"2023-05-20T23:53:23.964279Z","shell.execute_reply":"2023-05-20T23:53:23.962559Z","shell.execute_reply.started":"2023-05-20T23:53:23.953746Z"},"trusted":true},"outputs":[],"source":["def encode(texts):\n","    encoded_input = enc_tokenizer(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n","    with torch.no_grad():\n","        model_output = encoder(**encoded_input.to(encoder.device))\n","        embeddings = model_output.last_hidden_state\n","    return embeddings\n","\n","\n","def decode(embeddings, max_length=MAX_LEN, repetition_penalty=3.0, **kwargs):\n","    with torch.no_grad():\n","        out = decoder.generate(\n","            encoder_outputs=BaseModelOutput(last_hidden_state=embeddings), \n","            max_length=max_length, \n","            repetition_penalty=repetition_penalty,\n","            **kwargs\n","        )\n","        return [dec_tokenizer.decode(tokens, skip_special_tokens=True) for tokens in out]\n","    \n","\n","def calc_bleu(loader):\n","    original_text = []\n","    generated_text = []\n","    encoder.eval()\n","    decoder.eval()\n","\n","    for en, ru in tqdm(loader):\n","        embeds = encode(en)\n","        generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=None)\n","        \n","        original_text.extend(ru)\n","        generated_text.extend(generated)\n","\n","    return corpus_bleu([[text] for text in original_text], generated_text) * 100"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T23:53:39.330790Z","iopub.status.busy":"2023-05-20T23:53:39.330407Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaumenko-km\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/k.naumenko/MADE/NLP/wandb/run-20230521_044540-35jaru5p</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/35jaru5p' target=\"_blank\">experiment_4</a></strong> to <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/35jaru5p' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/35jaru5p</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[EPOCH 1]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [12:04<00:00,  3.89it/s] \n","100%|██████████| 149/149 [00:10<00:00, 14.44it/s]\n","100%|██████████| 157/157 [12:47<00:00,  4.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.481465419666879 val bleu: 7.520443114850823\n","[EPOCH 2]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:34<00:00,  4.06it/s] \n","100%|██████████| 149/149 [00:10<00:00, 14.56it/s]\n","100%|██████████| 157/157 [12:09<00:00,  4.65s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.0935654952222067 val bleu: 14.446332161079756\n","[EPOCH 3]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:38<00:00,  4.04it/s] \n","100%|██████████| 149/149 [00:10<00:00, 14.40it/s]\n","100%|██████████| 157/157 [10:49<00:00,  4.14s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.9358698561687597 val bleu: 18.0393771522862\n","[EPOCH 4]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:39<00:00,  4.03it/s] \n","100%|██████████| 149/149 [00:10<00:00, 14.43it/s]\n","100%|██████████| 157/157 [10:46<00:00,  4.12s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.8647736174948264 val bleu: 18.883952113572956\n","[EPOCH 5]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:31<00:00,  4.08it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.44it/s]\n","100%|██████████| 157/157 [09:55<00:00,  3.79s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.8324492169706614 val bleu: 20.688191561119112\n","[EPOCH 6]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:33<00:00,  4.06it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.45it/s]\n","100%|██████████| 157/157 [09:22<00:00,  3.58s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.8181486813814047 val bleu: 20.909259701147707\n","[EPOCH 7]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:32<00:00,  4.07it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.54it/s]\n","100%|██████████| 157/157 [09:11<00:00,  3.51s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.8099692319863594 val bleu: 21.286235918792013\n","[EPOCH 8]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:34<00:00,  4.06it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.43it/s]\n","100%|██████████| 157/157 [09:12<00:00,  3.52s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.8059835601973053 val bleu: 21.399760867574617\n","[EPOCH 9]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:30<00:00,  4.08it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.57it/s]\n","100%|██████████| 157/157 [09:14<00:00,  3.53s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.805214831893076 val bleu: 21.448090742136188\n","[EPOCH 10]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [11:34<00:00,  4.06it/s]\n","100%|██████████| 149/149 [00:10<00:00, 14.48it/s]\n","100%|██████████| 157/157 [09:17<00:00,  3.55s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 1.8045732034932846 val bleu: 21.423642001663367\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▆▅▃▃▃▃▂▂▃▃▂▃▂▂▃▂▂▂▂▂▃▃▂▂▂▂▁▂▂▂▂▁▂▂▂▁▃▃▂</td></tr><tr><td>val bleu</td><td>▁▁▁▁▃▃▃▃▆▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val loss</td><td>████▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.93026</td></tr><tr><td>val bleu</td><td>21.44809</td></tr><tr><td>val loss</td><td>1.80521</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_4</strong> at: <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/35jaru5p' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/35jaru5p</a><br/>Synced 6 W&B file(s), 141 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230521_044540-35jaru5p/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"nlp-lab2\",\n","    notes=\"baseline\",\n","    name='experiment_4',\n","    entity='naumenko-km',\n","    \n","    # track hyperparameters and run metadata\n","    config={\n","    \"learning_rate\": LR,\n","    \"encoder\": enc_name,\n","    \"decoder\": dec_name,\n","    \"epochs\": n_epochs,\n","    }\n",")\n","best_bleu = 0\n","val_bleu = 0\n","mean_val_loss = 10\n","iters = 1\n","\n","for i in range(1, n_epochs + 1):\n","    print(f'[EPOCH {i}]')\n","    tqdm_iterator = tqdm(train_loader)\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        encoder.train()\n","        decoder.train()\n","        x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","        y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","        y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","        embeds = encoder(**x.to(encoder.device))\n","        embeds = embeds.last_hidden_state.to(DEVICE)\n","\n","        loss = decoder(\n","            encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n","            labels=y.input_ids,\n","            decoder_attention_mask=y.attention_mask,\n","            return_dict=True\n","        ).loss\n","                \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        wandb.log({\"batch loss\": loss.item(), \"val loss\": mean_val_loss, 'val bleu': val_bleu}, step=iters)\n","\n","        if iters % log_each_n_iterations == 0:\n","            encoder.eval()\n","            decoder.eval()    \n","            en, ru = next(iter(generate_loader))\n","            embeds = encode(en)\n","            generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=None)\n","            example = wandb.Html(data=f'batches: {iters} <br> True: {ru[0]} <br> Generated: {generated[0]}')\n","            wandb.log({\"texts\": example}, step=iters)\n","        iters += 1\n","\n","    tqdm_iterator = tqdm(test_loader)\n","    val_loss = []\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        encoder.eval()\n","        decoder.eval()\n","        with torch.no_grad():\n","            x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","            y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","            y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","            embeds = encoder(**x.to(encoder.device))\n","            embeds = embeds.last_hidden_state.to(DEVICE)\n","\n","            loss = decoder(\n","                encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n","                labels=y.input_ids,\n","                decoder_attention_mask=y.attention_mask,\n","                return_dict=True\n","            ).loss\n","            val_loss.append(loss.item())\n","    \n","    mean_val_loss = np.mean(val_loss)\n","    val_bleu = calc_bleu(val_loader)\n","    print(\"val loss:\", mean_val_loss, 'val bleu:', val_bleu)\n","    scheduler.step()\n","    \n","    if val_bleu > best_bleu:\n","        best_bleu = val_bleu\n","        # torch.save(encoder.state_dict(), 'encoder.pt')\n","        # torch.save(decoder.state_dict(), 'decoder.pt')\n","        # print(f'best loss improved!')\n","\n","wandb.finish()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 149/149 [08:32<00:00,  3.44s/it]\n"]},{"data":{"text/plain":["21.265918481687468"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["calc_bleu(test_loader)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"homework.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
