{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lab assignment 02"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Neural Machine Translation in the wild\n","In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n","\n","Basic approach using RNNs as encoder and decoder is implemented for you. \n","\n","Your ultimate task is to use the techniques we've covered, e.g.\n","\n","* Optimization enhancements (e.g. learning rate decay)\n","\n","* Transformer/CNN/<whatever you select> encoder (with or without positional encoding)\n","\n","* attention/self-attention mechanism\n","\n","* pretraining the language models (for decoder and encoder)\n","\n","* or just fine-tunning BART/ELECTRA/... ;)\n","\n","to improve the translation quality. \n","\n","__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n","\n","Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:05.686629Z","iopub.status.busy":"2023-05-22T08:21:05.685932Z","iopub.status.idle":"2023-05-22T08:21:05.699981Z","shell.execute_reply":"2023-05-22T08:21:05.698296Z","shell.execute_reply.started":"2023-05-22T08:21:05.686586Z"},"trusted":true},"outputs":[],"source":["# Thanks to YSDA NLP course team for the data\n","# (who thanks tilda and deephack teams for the data in their turn)\n","\n","import os\n","path_do_data = 'data.txt'\n","if not os.path.exists(path_do_data):\n","    print(\"Dataset not found locally. Downloading from github.\")\n","    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T12:02:30.223431Z","iopub.status.busy":"2023-05-20T12:02:30.223038Z","iopub.status.idle":"2023-05-20T12:02:30.228043Z","shell.execute_reply":"2023-05-20T12:02:30.227012Z","shell.execute_reply.started":"2023-05-20T12:02:30.223395Z"},"trusted":true},"outputs":[],"source":["# Baseline solution BLEU score is quite low. Try to achieve at least __21__ BLEU on the test set. \n","# The checkpoints are:\n","\n","# * __21__ - minimal score to submit the homework, 30% of points\n","\n","# * __25__ - good score, 70% of points\n","\n","# * __27__ - excellent score, 100% of points"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:08.838671Z","iopub.status.busy":"2023-05-22T08:21:08.835504Z","iopub.status.idle":"2023-05-22T08:21:20.410245Z","shell.execute_reply":"2023-05-22T08:21:20.409262Z","shell.execute_reply.started":"2023-05-22T08:21:08.838624Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import random\n","import matplotlib.pyplot as plt\n","import time\n","\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel\n","from transformers.modeling_outputs import BaseModelOutput\n","from transformers import T5Model, T5Tokenizer, T5Config, T5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoConfig\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from nltk.translate.bleu_score import corpus_bleu\n","from IPython.display import clear_output\n","\n","import wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:20.412551Z","iopub.status.busy":"2023-05-22T08:21:20.412181Z","iopub.status.idle":"2023-05-22T08:21:30.512988Z","shell.execute_reply":"2023-05-22T08:21:30.512083Z","shell.execute_reply.started":"2023-05-22T08:21:20.412508Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaumenko-km\u001b[0m (\u001b[33mvector2text\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:34.056847Z","iopub.status.busy":"2023-05-22T08:21:34.056425Z","iopub.status.idle":"2023-05-22T08:21:34.293669Z","shell.execute_reply":"2023-05-22T08:21:34.292354Z","shell.execute_reply.started":"2023-05-22T08:21:34.056811Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num texts: 50000 50000\n","En max len: 518\n","Ru max len: 431\n"]}],"source":["with open('data.txt', 'r') as f:\n","    texts = f.read()\n","\n","texts = texts.split(sep='\\n')\n","texts = [row.split('\\t') for row in texts]\n","texts_en = [row[0] for row in texts if len(row) == 2]\n","texts_ru = [row[1] for row in texts if len(row) == 2]\n","\n","print('Num texts:', len(texts_en), len(texts_ru))\n","print('En max len:', max([len(row) for row in texts_en]))\n","print('Ru max len:', max([len(row) for row in texts_ru]))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:39.871990Z","iopub.status.busy":"2023-05-22T08:21:39.871632Z","iopub.status.idle":"2023-05-22T08:21:39.904807Z","shell.execute_reply":"2023-05-22T08:21:39.903267Z","shell.execute_reply.started":"2023-05-22T08:21:39.871958Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda', index=4)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["DEVICE = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n","MAX_LEN = 518\n","DEVICE"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:41.826085Z","iopub.status.busy":"2023-05-22T08:21:41.825115Z","iopub.status.idle":"2023-05-22T08:21:41.832698Z","shell.execute_reply":"2023-05-22T08:21:41.831557Z","shell.execute_reply.started":"2023-05-22T08:21:41.826032Z"},"trusted":true},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, texts_en, texts_ru):\n","        self.texts_en = texts_en\n","        self.texts_ru = texts_ru\n","        \n","    def __len__(self):\n","        return len(self.texts_en)\n","    \n","    def __getitem__(self, idx):\n","        return self.texts_en[idx], self.texts_ru[idx]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:42.786346Z","iopub.status.busy":"2023-05-22T08:21:42.785019Z","iopub.status.idle":"2023-05-22T08:21:42.850737Z","shell.execute_reply":"2023-05-22T08:21:42.849843Z","shell.execute_reply.started":"2023-05-22T08:21:42.786304Z"},"trusted":true},"outputs":[],"source":["train_texts_en, val_texts_en, train_texts_ru, val_texts_ru = train_test_split(texts_en, texts_ru, test_size=0.05, random_state=42)\n","train_texts_en, test_texts_en, train_texts_ru, test_texts_ru = train_test_split(train_texts_en, train_texts_ru, test_size=0.05, random_state=42)\n","\n","train_dataset = TextDataset(train_texts_en, train_texts_ru)\n","val_dataset = TextDataset(val_texts_en, val_texts_ru)\n","test_dataset = TextDataset(test_texts_en, test_texts_ru)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:54.945778Z","iopub.status.busy":"2023-05-22T08:21:54.945407Z","iopub.status.idle":"2023-05-22T08:21:54.950465Z","shell.execute_reply":"2023-05-22T08:21:54.949314Z","shell.execute_reply.started":"2023-05-22T08:21:54.945749Z"},"trusted":true},"outputs":[],"source":["n_epochs = 12\n","batch_size = 16\n","log_each_n_iterations = 200\n","generate_n = 1"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:22:24.346643Z","iopub.status.busy":"2023-05-22T08:22:24.345900Z","iopub.status.idle":"2023-05-22T08:22:41.260831Z","shell.execute_reply":"2023-05-22T08:22:41.259861Z","shell.execute_reply.started":"2023-05-22T08:22:24.346603Z"},"trusted":true},"outputs":[],"source":["random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size)\n","test_loader = DataLoader(test_dataset, batch_size)\n","generate_loader = DataLoader(val_dataset, generate_n, shuffle=True)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["model_name = 'cointegrated/rut5-base-multitask'\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n","\n","config = T5Config(vocab_size=tokenizer.vocab_size, decoder_start_token_id=0)\n","model =  T5ForConditionalGeneration(config)\n","model.to(DEVICE);"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["LR = 1e-5\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T11:39:10.142355Z","iopub.status.busy":"2023-05-22T11:39:10.141586Z","iopub.status.idle":"2023-05-22T11:39:10.151932Z","shell.execute_reply":"2023-05-22T11:39:10.150902Z","shell.execute_reply.started":"2023-05-22T11:39:10.142317Z"},"trusted":true},"outputs":[],"source":["def generate(en, max_length=MAX_LEN, repetition_penalty=None):\n","    model.eval()\n","    with torch.no_grad():\n","        x = tokenizer(en, padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt').to(DEVICE)\n","        out = model.generate(**x, max_length=MAX_LEN, repetition_penalty=None)\n","        generated = [tokenizer.decode(tokens, skip_special_tokens=True) for tokens in out]\n","        return generated\n","    \n","\n","def calc_bleu(loader):\n","    original_text = []\n","    generated_text = []\n","    for en, ru in tqdm(loader):\n","        generated = generate(en)\n","        original_text.extend(ru)\n","        generated_text.extend(generated)\n","    return corpus_bleu([[text] for text in original_text], generated_text) * 100"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:36:07.921017Z","iopub.status.busy":"2023-05-22T08:36:07.920633Z","iopub.status.idle":"2023-05-22T11:23:49.040293Z","shell.execute_reply":"2023-05-22T11:23:49.039393Z","shell.execute_reply.started":"2023-05-22T08:36:07.920986Z"},"trusted":true},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.15.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/k.naumenko/MADE/NLP/wandb/run-20230523_020724-1brdtp0j</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/1brdtp0j' target=\"_blank\">t5_1</a></strong> to <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/1brdtp0j' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/1brdtp0j</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[EPOCH 1]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [06:16<00:00,  7.49it/s] \n","100%|██████████| 149/149 [00:04<00:00, 32.26it/s]\n","100%|██████████| 157/157 [05:47<00:00,  2.21s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 4.887052372798023 val bleu: 14.367539879601225\n","[EPOCH 2]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [05:44<00:00,  8.18it/s]\n","100%|██████████| 149/149 [00:04<00:00, 34.81it/s]\n","100%|██████████| 157/157 [05:14<00:00,  2.00s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 4.255457145255684 val bleu: 20.49577676135446\n","[EPOCH 3]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [05:54<00:00,  7.96it/s]\n","100%|██████████| 149/149 [00:04<00:00, 31.03it/s]\n","100%|██████████| 157/157 [07:13<00:00,  2.76s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.885418815100753 val bleu: 19.259078858520105\n","[EPOCH 4]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [05:58<00:00,  7.86it/s]\n","100%|██████████| 149/149 [00:04<00:00, 35.12it/s]\n","100%|██████████| 157/157 [07:33<00:00,  2.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.626132713868314 val bleu: 18.5123030085037\n","[EPOCH 5]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [06:02<00:00,  7.77it/s]\n","100%|██████████| 149/149 [00:04<00:00, 33.41it/s]\n","100%|██████████| 157/157 [05:33<00:00,  2.12s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.487332924900439 val bleu: 22.921628029687852\n","[EPOCH 6]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [05:57<00:00,  7.89it/s]\n","100%|██████████| 149/149 [00:04<00:00, 35.23it/s]\n","100%|██████████| 157/157 [04:59<00:00,  1.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.3929932181467146 val bleu: 26.601592643704784\n","[EPOCH 7]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [05:55<00:00,  7.94it/s]\n","100%|██████████| 149/149 [00:04<00:00, 34.41it/s]\n","100%|██████████| 157/157 [04:58<00:00,  1.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.301370926351355 val bleu: 27.72791526248802\n","[EPOCH 8]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [05:59<00:00,  7.83it/s]\n","100%|██████████| 149/149 [00:04<00:00, 35.42it/s]\n","100%|██████████| 157/157 [04:28<00:00,  1.71s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.2161433552735605 val bleu: 29.333407628048725\n","[EPOCH 9]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [05:56<00:00,  7.90it/s]\n","100%|██████████| 149/149 [00:04<00:00, 32.66it/s]\n","100%|██████████| 157/157 [04:15<00:00,  1.63s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.179365705323699 val bleu: 32.409613299286875\n","[EPOCH 10]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [06:17<00:00,  7.48it/s]\n","100%|██████████| 149/149 [00:04<00:00, 35.01it/s]\n","100%|██████████| 157/157 [03:42<00:00,  1.41s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.140476950863064 val bleu: 34.415834088591566\n","[EPOCH 11]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [05:57<00:00,  7.88it/s]\n","100%|██████████| 149/149 [00:04<00:00, 32.76it/s]\n","100%|██████████| 157/157 [03:47<00:00,  1.45s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.109533921184156 val bleu: 34.92120809002799\n","[EPOCH 12]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [06:06<00:00,  7.69it/s]\n","100%|██████████| 149/149 [00:04<00:00, 35.06it/s]\n","100%|██████████| 157/157 [03:24<00:00,  1.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.0746183811418164 val bleu: 37.33281026958067\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▆▅▅▄▄▅▄▄▃▄▃▃▃▃▄▃▂▂▃▂▂▃▂▂▃▃▃▂▂▁▂▁▂▁▂▂▂▂▁</td></tr><tr><td>val bleu</td><td>▁▁▁▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>val loss</td><td>███▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>2.95841</td></tr><tr><td>val bleu</td><td>34.92121</td></tr><tr><td>val loss</td><td>3.10953</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">t5_1</strong> at: <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/1brdtp0j' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/1brdtp0j</a><br/>Synced 6 W&B file(s), 169 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230523_020724-1brdtp0j/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"nlp-lab2\",\n","    notes=\"baseline\",\n","    name='t5_1',\n","    entity='naumenko-km',\n","    \n","    # track hyperparameters and run metadata\n","    config={\n","    \"learning_rate\": LR,\n","    \"encoder\": model_name,\n","    \"decoder\": model_name,\n","    \"epochs\": n_epochs,\n","    }\n",")\n","best_bleu = 0\n","val_bleu = 0\n","mean_val_loss = 10\n","iters = 1\n","\n","for i in range(1, n_epochs + 1):\n","    print(f'[EPOCH {i}]')\n","    tqdm_iterator = tqdm(train_loader)\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        model.train()\n","        x = tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","        y = tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","        y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","        loss = model(\n","            **x,\n","            labels=y.input_ids,\n","            decoder_attention_mask=y.attention_mask,\n","            return_dict=True\n","        ).loss\n","                \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        wandb.log({\"batch loss\": loss.item(), \"val loss\": mean_val_loss, 'val bleu': val_bleu}, step=iters)\n","\n","        if iters % log_each_n_iterations == 0:\n","            en, ru = next(iter(generate_loader))\n","            generated = generate(en)\n","            example = wandb.Html(data=f'batches: {iters} <br> True: {ru[0]} <br> Generated: {generated[0]}')\n","            wandb.log({\"texts\": example}, step=iters)\n","        iters += 1\n","    tqdm_iterator = tqdm(test_loader)\n","    val_loss = []\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        model.eval()\n","        with torch.no_grad():\n","            x = tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","            y = tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","            y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","            loss = model(\n","                **x,\n","                labels=y.input_ids,\n","                decoder_attention_mask=y.attention_mask,\n","                return_dict=True\n","            ).loss\n","            val_loss.append(loss.item())\n","    mean_val_loss = np.mean(val_loss)\n","    val_bleu = calc_bleu(val_loader)\n","    print(\"val loss:\", mean_val_loss, 'val bleu:', val_bleu)\n","    scheduler.step()\n","    \n","    if val_bleu > best_bleu:\n","        best_bleu = val_bleu\n","        # torch.save(encoder.state_dict(), 'encoder.pt')\n","        # torch.save(decoder.state_dict(), 'decoder.pt')\n","        # print(f'best loss improved!')\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T12:18:15.915965Z","iopub.status.busy":"2023-05-22T12:18:15.915157Z","iopub.status.idle":"2023-05-22T12:22:04.172075Z","shell.execute_reply":"2023-05-22T12:22:04.171074Z","shell.execute_reply.started":"2023-05-22T12:18:15.915928Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 149/149 [03:27<00:00,  1.39s/it]\n"]},{"data":{"text/plain":["36.78979854750574"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["calc_bleu(test_loader)"]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"homework.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
