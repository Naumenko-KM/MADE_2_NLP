{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lab assignment 02"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Neural Machine Translation in the wild\n","In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n","\n","Basic approach using RNNs as encoder and decoder is implemented for you. \n","\n","Your ultimate task is to use the techniques we've covered, e.g.\n","\n","* Optimization enhancements (e.g. learning rate decay)\n","\n","* Transformer/CNN/<whatever you select> encoder (with or without positional encoding)\n","\n","* attention/self-attention mechanism\n","\n","* pretraining the language models (for decoder and encoder)\n","\n","* or just fine-tunning BART/ELECTRA/... ;)\n","\n","to improve the translation quality. \n","\n","__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n","\n","Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:05.686629Z","iopub.status.busy":"2023-05-22T08:21:05.685932Z","iopub.status.idle":"2023-05-22T08:21:05.699981Z","shell.execute_reply":"2023-05-22T08:21:05.698296Z","shell.execute_reply.started":"2023-05-22T08:21:05.686586Z"},"trusted":true},"outputs":[],"source":["# Thanks to YSDA NLP course team for the data\n","# (who thanks tilda and deephack teams for the data in their turn)\n","\n","import os\n","path_do_data = 'data.txt'\n","if not os.path.exists(path_do_data):\n","    print(\"Dataset not found locally. Downloading from github.\")\n","    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T12:02:30.223431Z","iopub.status.busy":"2023-05-20T12:02:30.223038Z","iopub.status.idle":"2023-05-20T12:02:30.228043Z","shell.execute_reply":"2023-05-20T12:02:30.227012Z","shell.execute_reply.started":"2023-05-20T12:02:30.223395Z"},"trusted":true},"outputs":[],"source":["# Baseline solution BLEU score is quite low. Try to achieve at least __21__ BLEU on the test set. \n","# The checkpoints are:\n","\n","# * __21__ - minimal score to submit the homework, 30% of points\n","\n","# * __25__ - good score, 70% of points\n","\n","# * __27__ - excellent score, 100% of points"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:08.838671Z","iopub.status.busy":"2023-05-22T08:21:08.835504Z","iopub.status.idle":"2023-05-22T08:21:20.410245Z","shell.execute_reply":"2023-05-22T08:21:20.409262Z","shell.execute_reply.started":"2023-05-22T08:21:08.838624Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import random\n","import matplotlib.pyplot as plt\n","import time\n","\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel\n","from transformers.modeling_outputs import BaseModelOutput\n","from transformers import T5Model, T5Tokenizer, T5Config, T5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoConfig\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from nltk.translate.bleu_score import corpus_bleu\n","from IPython.display import clear_output\n","\n","import wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:20.412551Z","iopub.status.busy":"2023-05-22T08:21:20.412181Z","iopub.status.idle":"2023-05-22T08:21:30.512988Z","shell.execute_reply":"2023-05-22T08:21:30.512083Z","shell.execute_reply.started":"2023-05-22T08:21:20.412508Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaumenko-km\u001b[0m (\u001b[33mvector2text\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:34.056847Z","iopub.status.busy":"2023-05-22T08:21:34.056425Z","iopub.status.idle":"2023-05-22T08:21:34.293669Z","shell.execute_reply":"2023-05-22T08:21:34.292354Z","shell.execute_reply.started":"2023-05-22T08:21:34.056811Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num texts: 50000 50000\n","En max len: 518\n","Ru max len: 431\n"]}],"source":["with open('data.txt', 'r') as f:\n","    texts = f.read()\n","\n","texts = texts.split(sep='\\n')\n","texts = [row.split('\\t') for row in texts]\n","texts_en = [row[0] for row in texts if len(row) == 2]\n","texts_ru = [row[1] for row in texts if len(row) == 2]\n","\n","print('Num texts:', len(texts_en), len(texts_ru))\n","print('En max len:', max([len(row) for row in texts_en]))\n","print('Ru max len:', max([len(row) for row in texts_ru]))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:39.871990Z","iopub.status.busy":"2023-05-22T08:21:39.871632Z","iopub.status.idle":"2023-05-22T08:21:39.904807Z","shell.execute_reply":"2023-05-22T08:21:39.903267Z","shell.execute_reply.started":"2023-05-22T08:21:39.871958Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda', index=7)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["DEVICE = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')\n","MAX_LEN = 518\n","DEVICE"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:41.826085Z","iopub.status.busy":"2023-05-22T08:21:41.825115Z","iopub.status.idle":"2023-05-22T08:21:41.832698Z","shell.execute_reply":"2023-05-22T08:21:41.831557Z","shell.execute_reply.started":"2023-05-22T08:21:41.826032Z"},"trusted":true},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, texts_en, texts_ru):\n","        self.texts_en = texts_en\n","        self.texts_ru = texts_ru\n","        \n","    def __len__(self):\n","        return len(self.texts_en)\n","    \n","    def __getitem__(self, idx):\n","        return self.texts_en[idx], self.texts_ru[idx]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:42.786346Z","iopub.status.busy":"2023-05-22T08:21:42.785019Z","iopub.status.idle":"2023-05-22T08:21:42.850737Z","shell.execute_reply":"2023-05-22T08:21:42.849843Z","shell.execute_reply.started":"2023-05-22T08:21:42.786304Z"},"trusted":true},"outputs":[],"source":["train_texts_en, val_texts_en, train_texts_ru, val_texts_ru = train_test_split(texts_en, texts_ru, test_size=0.05, random_state=42)\n","train_texts_en, test_texts_en, train_texts_ru, test_texts_ru = train_test_split(train_texts_en, train_texts_ru, test_size=0.05, random_state=42)\n","\n","train_dataset = TextDataset(train_texts_en, train_texts_ru)\n","val_dataset = TextDataset(val_texts_en, val_texts_ru)\n","test_dataset = TextDataset(test_texts_en, test_texts_ru)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:21:54.945778Z","iopub.status.busy":"2023-05-22T08:21:54.945407Z","iopub.status.idle":"2023-05-22T08:21:54.950465Z","shell.execute_reply":"2023-05-22T08:21:54.949314Z","shell.execute_reply.started":"2023-05-22T08:21:54.945749Z"},"trusted":true},"outputs":[],"source":["n_epochs = 12\n","batch_size = 16\n","log_each_n_iterations = 200\n","generate_n = 1"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:22:24.346643Z","iopub.status.busy":"2023-05-22T08:22:24.345900Z","iopub.status.idle":"2023-05-22T08:22:41.260831Z","shell.execute_reply":"2023-05-22T08:22:41.259861Z","shell.execute_reply.started":"2023-05-22T08:22:24.346603Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size)\n","test_loader = DataLoader(test_dataset, batch_size)\n","generate_loader = DataLoader(val_dataset, generate_n, shuffle=True)\n","\n","\n","enc_name = 'distilbert-base-multilingual-cased'\n","dec_name = \"cointegrated/rut5-base-multitask\"\n","\n","enc_tokenizer = AutoTokenizer.from_pretrained(enc_name)\n","encoder = AutoModel.from_pretrained(enc_name).to(DEVICE)\n","\n","dec_tokenizer = AutoTokenizer.from_pretrained(dec_name, use_fast=False)\n","config = T5Config(vocab_size=dec_tokenizer.vocab_size, d_model=encoder.config.dim, decoder_start_token_id=0)\n","decoder = T5ForConditionalGeneration(config).to(DEVICE)\n","\n","for p in decoder.encoder.parameters():\n","    p.requires_grad = False\n","for p in decoder.decoder.parameters():\n","    p.requires_grad = True\n","\n","\n","LR = 1e-5\n","optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T11:39:10.142355Z","iopub.status.busy":"2023-05-22T11:39:10.141586Z","iopub.status.idle":"2023-05-22T11:39:10.151932Z","shell.execute_reply":"2023-05-22T11:39:10.150902Z","shell.execute_reply.started":"2023-05-22T11:39:10.142317Z"},"trusted":true},"outputs":[],"source":["def encode(texts):\n","    encoded_input = enc_tokenizer(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n","    with torch.no_grad():\n","        model_output = encoder(**encoded_input.to(encoder.device))\n","        embeddings = model_output.last_hidden_state\n","    return embeddings\n","\n","\n","def decode(embeddings, max_length=MAX_LEN, repetition_penalty=None, **kwargs):\n","    with torch.no_grad():\n","        out = decoder.generate(\n","            encoder_outputs=BaseModelOutput(last_hidden_state=embeddings), \n","            max_length=max_length, \n","            repetition_penalty=repetition_penalty,\n","            **kwargs\n","        )\n","        return [dec_tokenizer.decode(tokens, skip_special_tokens=True) for tokens in out]\n","    \n","\n","def calc_bleu(loader):\n","    original_text = []\n","    generated_text = []\n","    encoder.eval()\n","    decoder.eval()\n","\n","    for en, ru in tqdm(loader):\n","        embeds = encode(en)\n","        generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=None)\n","        \n","        original_text.extend(ru)\n","        generated_text.extend(generated)\n","\n","    return corpus_bleu([[text] for text in original_text], generated_text) * 100"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T08:36:07.921017Z","iopub.status.busy":"2023-05-22T08:36:07.920633Z","iopub.status.idle":"2023-05-22T11:23:49.040293Z","shell.execute_reply":"2023-05-22T11:23:49.039393Z","shell.execute_reply.started":"2023-05-22T08:36:07.920986Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaumenko-km\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/k.naumenko/MADE/NLP/wandb/run-20230523_021623-wvc5jhq8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/wvc5jhq8' target=\"_blank\">bert-t5_1</a></strong> to <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/naumenko-km/nlp-lab2' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/wvc5jhq8' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/wvc5jhq8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[EPOCH 1]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:52<00:00,  5.97it/s]\n","100%|██████████| 149/149 [00:06<00:00, 21.94it/s]\n","100%|██████████| 157/157 [12:09<00:00,  4.64s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 4.230609900199327 val bleu: 8.224330881846848\n","[EPOCH 2]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:47<00:00,  6.03it/s]\n","100%|██████████| 149/149 [00:06<00:00, 21.87it/s]\n","100%|██████████| 157/157 [09:41<00:00,  3.71s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.648887389458266 val bleu: 14.586010616101591\n","[EPOCH 3]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:54<00:00,  5.95it/s]\n","100%|██████████| 149/149 [00:07<00:00, 20.56it/s]\n","100%|██████████| 157/157 [06:51<00:00,  2.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.295438775280178 val bleu: 24.229836650376182\n","[EPOCH 4]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:56<00:00,  5.92it/s]\n","100%|██████████| 149/149 [00:06<00:00, 21.66it/s]\n","100%|██████████| 157/157 [05:46<00:00,  2.20s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.1353041549657017 val bleu: 30.2758066073848\n","[EPOCH 5]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:54<00:00,  5.94it/s]\n","100%|██████████| 149/149 [00:06<00:00, 21.72it/s]\n","100%|██████████| 157/157 [04:12<00:00,  1.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 3.015691159555576 val bleu: 39.05871256413146\n","[EPOCH 6]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:55<00:00,  5.94it/s]\n","100%|██████████| 149/149 [00:07<00:00, 20.65it/s]\n","100%|██████████| 157/157 [03:48<00:00,  1.45s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.911944973388774 val bleu: 41.954569732378545\n","[EPOCH 7]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:55<00:00,  5.93it/s]\n","100%|██████████| 149/149 [00:06<00:00, 21.33it/s]\n","100%|██████████| 157/157 [03:04<00:00,  1.18s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.856419656100689 val bleu: 44.59903790101553\n","[EPOCH 8]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:54<00:00,  5.94it/s]\n","100%|██████████| 149/149 [00:07<00:00, 21.23it/s]\n","100%|██████████| 157/157 [02:30<00:00,  1.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.8103838870989395 val bleu: 44.65171447961292\n","[EPOCH 9]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:55<00:00,  5.93it/s]\n","100%|██████████| 149/149 [00:06<00:00, 21.37it/s]\n","100%|██████████| 157/157 [02:30<00:00,  1.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.7655360202661297 val bleu: 45.60496331661011\n","[EPOCH 10]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [07:56<00:00,  5.92it/s]\n","100%|██████████| 149/149 [00:07<00:00, 20.88it/s]\n","100%|██████████| 157/157 [02:35<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.741258884436332 val bleu: 45.82701914670654\n","[EPOCH 11]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [08:07<00:00,  5.78it/s]\n","100%|██████████| 149/149 [00:07<00:00, 20.67it/s]\n","100%|██████████| 157/157 [02:39<00:00,  1.02s/it]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.7173241968922968 val bleu: 45.74054120761786\n","[EPOCH 12]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2820/2820 [08:09<00:00,  5.77it/s]\n","100%|██████████| 149/149 [00:07<00:00, 20.89it/s]\n","100%|██████████| 157/157 [02:35<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["val loss: 2.698839110816085 val bleu: 46.044348207032385\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>██▃▅▄▄▅▂▃▃▂▃▃▂▃▃▃▂▃▁▁▂▂▃▃▁▃▁▂▃▂▃▁▂▃▃▂▃▂▂</td></tr><tr><td>val bleu</td><td>▁▁▁▂▂▂▂▃▃▃▅▅▅▅▆▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>val loss</td><td>███▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>2.39812</td></tr><tr><td>val bleu</td><td>45.74054</td></tr><tr><td>val loss</td><td>2.71732</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-t5_1</strong> at: <a href='https://wandb.ai/naumenko-km/nlp-lab2/runs/wvc5jhq8' target=\"_blank\">https://wandb.ai/naumenko-km/nlp-lab2/runs/wvc5jhq8</a><br/>Synced 6 W&B file(s), 169 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230523_021623-wvc5jhq8/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"nlp-lab2\",\n","    notes=\"baseline\",\n","    name='bert-t5_1',\n","    entity='naumenko-km',\n","    \n","    # track hyperparameters and run metadata\n","    config={\n","    \"learning_rate\": LR,\n","    \"encoder\": enc_name,\n","    \"decoder\": dec_name,\n","    \"epochs\": n_epochs,\n","    }\n",")\n","best_bleu = 0\n","val_bleu = 0\n","mean_val_loss = 10\n","iters = 1\n","\n","for i in range(1, n_epochs + 1):\n","    print(f'[EPOCH {i}]')\n","    tqdm_iterator = tqdm(train_loader)\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        encoder.train()\n","        decoder.train()\n","        x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","        y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","        y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","        embeds = encoder(**x.to(encoder.device))\n","        embeds = embeds.last_hidden_state.to(DEVICE)\n","\n","        loss = decoder(\n","            encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n","            labels=y.input_ids,\n","            decoder_attention_mask=y.attention_mask,\n","            return_dict=True\n","        ).loss\n","                \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        wandb.log({\"batch loss\": loss.item(), \"val loss\": mean_val_loss, 'val bleu': val_bleu}, step=iters)\n","\n","        if iters % log_each_n_iterations == 0:\n","            encoder.eval()\n","            decoder.eval()    \n","            en, ru = next(iter(generate_loader))\n","            embeds = encode(en)\n","            generated = decode(embeds, max_length=MAX_LEN, repetition_penalty=3.0)\n","            example = wandb.Html(data=f'batches: {iters} <br> True: {ru[0]} <br> Generated: {generated[0]}')\n","            wandb.log({\"texts\": example}, step=iters)\n","        iters += 1\n","\n","    tqdm_iterator = tqdm(test_loader)\n","    val_loss = []\n","    for text_en_batch, text_ru_batch in tqdm_iterator:\n","        encoder.eval()\n","        decoder.eval()\n","        with torch.no_grad():\n","            x = enc_tokenizer(text_en_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","            y = dec_tokenizer(text_ru_batch, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n","\n","            y.input_ids[y.input_ids == 0] = -100  # не учитываем паддинг в лоссе\n","            embeds = encoder(**x.to(encoder.device))\n","            embeds = embeds.last_hidden_state.to(DEVICE)\n","\n","            loss = decoder(\n","                encoder_outputs=BaseModelOutput(last_hidden_state=embeds),\n","                labels=y.input_ids,\n","                decoder_attention_mask=y.attention_mask,\n","                return_dict=True\n","            ).loss\n","            val_loss.append(loss.item())\n","    \n","    mean_val_loss = np.mean(val_loss)\n","    val_bleu = calc_bleu(val_loader)\n","    print(\"val loss:\", mean_val_loss, 'val bleu:', val_bleu)\n","    scheduler.step()\n","    \n","    if val_bleu > best_bleu:\n","        best_bleu = val_bleu\n","        # torch.save(encoder.state_dict(), 'encoder.pt')\n","        # torch.save(decoder.state_dict(), 'decoder.pt')\n","        # print(f'best loss improved!')\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-22T12:18:15.915965Z","iopub.status.busy":"2023-05-22T12:18:15.915157Z","iopub.status.idle":"2023-05-22T12:22:04.172075Z","shell.execute_reply":"2023-05-22T12:22:04.171074Z","shell.execute_reply.started":"2023-05-22T12:18:15.915928Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 149/149 [02:25<00:00,  1.02it/s]\n"]},{"data":{"text/plain":["46.86642806376114"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["calc_bleu(test_loader)"]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"homework.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
